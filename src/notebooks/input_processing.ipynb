{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e95c8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5f73d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc9ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 1234\n",
    "\n",
    "# Python & NumPy\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Determinism flags\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c89c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = torch.randn(1, 512, device=device)\n",
    "bottleneck_input = torch.randn(256, 32, device=device)\n",
    "decoder_first_input = torch.randn(256, 32, device=device)\n",
    "decoder_last_input = torch.randn(64, 256, device=device)\n",
    "out_input = torch.randn(16, 512, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c498f9f",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce1ba420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=15, s=2, p=7, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'lrelu' or 'relu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DeconvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvTranspose1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=4, s=2, p=1, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'relu' or 'lrelu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.deconv(x)))\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block: (Conv -> BN -> ReLU) x2 + skip\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, k=7, p=3, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n1 = nn.BatchNorm1d(ch)\n",
    "        self.c2 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n2 = nn.BatchNorm1d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.n1(self.c1(x)))\n",
    "        h = self.n2(self.c2(h))\n",
    "        return F.relu(x + h)\n",
    "    \n",
    "class MultiScaleResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale residual block: parallel conv branches (k=3,5,7) then fuse.\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=3, padding=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=5, padding=2, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b7 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=7, padding=3, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.b3(x) + self.b5(x) + self.b7(x)\n",
    "        h = self.fuse(h)\n",
    "        return F.relu(x + h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b6d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Generator (U-Net-ish + Res bottleneck)\n",
    "class GeneratorCNNWGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN U-Net-ish generator for EEG denoising (WGAN).\n",
    "    Input : (B, 1, 512) noisy_norm\n",
    "    Output: (B, 1, 512) clean_norm_hat\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = ConvBlock1D(1, base_ch,       k=16, s=2, p=7, bias=bias, act=\"lrelu\")      # 512 -> 256\n",
    "        self.e2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.e3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.e4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "\n",
    "        # Bottleneck\n",
    "        bn_ch = base_ch * 8\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            ResBlock1D(bn_ch, k=7, p=3, bias=bias) for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        # Decoder (concat doubles channels)\n",
    "        self.d1 = DeconvBlock1D(bn_ch, base_ch*4,   k=4, s=2, p=1, bias=bias, act=\"relu\")     # 32 -> 64\n",
    "        self.d2 = DeconvBlock1D(base_ch*8, base_ch*2, k=4, s=2, p=1,bias=bias, act=\"relu\")   # 64 -> 128\n",
    "        self.d3 = DeconvBlock1D(base_ch*4, base_ch,   k=4, s=2, p=1, bias=bias, act=\"relu\")   # 128 -> 256\n",
    "        self.d4 = DeconvBlock1D(base_ch*2, base_ch//2, k=4, s=2, p=1, bias=bias, act=\"relu\")  # 256 -> 512\n",
    "\n",
    "        # Head (linear output recommended for normalized signals)\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, kernel_size=7, stride=1, padding=3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        # Encoder\n",
    "        s1 = self.e1(y)   # (B, base, 256)\n",
    "        s2 = self.e2(s1)  # (B, 2b, 128)\n",
    "        s3 = self.e3(s2)  # (B, 4b, 64)\n",
    "        s4 = self.e4(s3)  # (B, 8b, 32)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(s4)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        d1 = self.d1(b)                  # (B, 4b, 64)\n",
    "        d1 = torch.cat([d1, s3], dim=1)  # (B, 8b, 64)\n",
    "\n",
    "        d2 = self.d2(d1)                 # (B, 2b, 128)\n",
    "        d2 = torch.cat([d2, s2], dim=1)  # (B, 4b, 128)\n",
    "\n",
    "        d3 = self.d3(d2)                 # (B, b, 256)\n",
    "        d3 = torch.cat([d3, s1], dim=1)  # (B, 2b, 256)\n",
    "\n",
    "        d4 = self.d4(d3)                 # (B, b/2, 512)\n",
    "\n",
    "        return self.out(d4)              # (B, 1, 512)\n",
    "    \n",
    "# Patch Critic (shared by CNN/ResCNN)\n",
    "class CriticPatch1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional PatchGAN critic for WGAN:\n",
    "      D(y, x) -> patch scores\n",
    "    y,x: (B,1,512)\n",
    "    output: (B,1,32)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(2, base_ch, kernel_size=16, stride=2, padding=7, bias=bias)  # 512 -> 256\n",
    "        self.c2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.c3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.c4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "        self.out = nn.Conv1d(base_ch*8, 1, kernel_size=7, stride=1, padding=3, bias=bias)   # 32 -> 32\n",
    "\n",
    "    def forward(self, y, x):\n",
    "        h = torch.cat([y, x], dim=1)  # (B,2,512)\n",
    "        h = F.leaky_relu(self.c1(h), 0.2, inplace=True)\n",
    "        h = self.c2(h)\n",
    "        h = self.c3(h)\n",
    "        h = self.c4(h)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af16c6",
   "metadata": {},
   "source": [
    "# Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da315182",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS = True\n",
    "DATA_MODE = 5 # up to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaf903ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d5_b\n",
      "G: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d5_b\\cnn_G_20260114_024826.pth\n",
      "D: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d5_b\\cnn_D_20260114_024826.pth\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(f\"../models/main3_d{DATA_MODE}_{\"b\" if BIAS else \"nb\"}/\")\n",
    "print(data_path)\n",
    "\n",
    "pattern = re.compile(r\"^cnn_([DG])_\\d{8}_\\d{6}\\.pth$\")\n",
    "\n",
    "cnn_G_path = None\n",
    "cnn_D_path = None\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "    m = pattern.match(f)\n",
    "    if m:\n",
    "        full = os.path.join(data_path, f)\n",
    "        if m.group(1) == \"G\":\n",
    "            cnn_G_path = full\n",
    "        else:\n",
    "            cnn_D_path = full\n",
    "\n",
    "print(\"G:\", cnn_G_path)\n",
    "print(\"D:\", cnn_D_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005e7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorCNNWGAN(\n",
      "  (e1): ConvBlock1D(\n",
      "    (conv): Conv1d(1, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d1): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d2): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d3): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(128, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d4): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(64, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "CriticPatch1D(\n",
      "  (c1): Conv1d(2, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "  (c2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(256, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_14912\\700924479.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_14912\\700924479.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = GeneratorCNNWGAN(bias=BIAS).to(device)\n",
    "D = CriticPatch1D(bias=BIAS).to(device)\n",
    "\n",
    "G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
    "D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n",
    "\n",
    "print(G.eval())\n",
    "print(D.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3096f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_CONFIGS = {\n",
    "    \"Q4.12\": dict(frac_bits=12, int_bits=4, dtype=np.int16),\n",
    "    \"Q10.10\": dict(frac_bits=10, int_bits=10, dtype=np.int32),\n",
    "    \"Q9.14\": dict(frac_bits=14, int_bits=10, dtype=np.int32),\n",
    "}\n",
    "\n",
    "def float_to_q(x, frac_bits, int_bits, dtype):\n",
    "    scale = 1 << frac_bits\n",
    "    total_bits = int_bits + frac_bits\n",
    "    min_val = -(1 << (total_bits - 1))\n",
    "    max_val = (1 << (total_bits - 1)) - 1\n",
    "\n",
    "    xq = np.round(x * scale)\n",
    "    xq = np.clip(xq, min_val, max_val)\n",
    "    return xq.astype(dtype)\n",
    "\n",
    "def q_to_float(x, frac_bits):\n",
    "    return x.astype(np.float32) / (1 << frac_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c5d3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE =  \"Q9.14\" # \"Q4.12\", \"Q10.10\",\"Q9.14\", or \"FLOAT\"\n",
    "\n",
    "TIME_REPEAT = {\n",
    "    \"encoder\":    [256, 128, 64, 32],\n",
    "    \"bottleneck\": [32]*8,\n",
    "    \"decoder\":    [64, 128, 256, 512],\n",
    "    \"out\":        [512]\n",
    "}\n",
    "\n",
    "if TYPE == \"FLOAT\":\n",
    "    MODE = \"FLOAT\"\n",
    "    DTYPE = np.float32\n",
    "else:\n",
    "    MODE = \"FIXED\"\n",
    "    cfg = Q_CONFIGS[TYPE]\n",
    "    FRAC_BITS = cfg[\"frac_bits\"]\n",
    "    INT_BITS  = cfg[\"int_bits\"]\n",
    "    DTYPE     = cfg[\"dtype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611a195",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52640b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.abspath(f\"../models/sample_output_{TYPE}/\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1a97d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DECODER LAST OUTPUT =====\n",
      "Shape      : (1, 512)\n",
      "Total vals : 512\n"
     ]
    }
   ],
   "source": [
    "# Encoder input\n",
    "G.eval()\n",
    "encoder_input_batched = encoder_input.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_all = G(encoder_input_batched)\n",
    "\n",
    "out_2d_all = out_all.squeeze(0)\n",
    "out_f_all = out_2d_all.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "assert out_f_all.ndim == 2, \"Expected 2D output [x, y]\"\n",
    "X_all, Y_all = out_f_all.shape\n",
    "\n",
    "print(\"===== DECODER LAST OUTPUT =====\")\n",
    "print(f\"Shape      : ({X_all}, {Y_all})\")\n",
    "print(f\"Total vals : {X_all * Y_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ddce75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DECODER LAST OUTPUT =====\n",
      "Shape      : (16, 512)\n",
      "Total vals : 8192\n"
     ]
    }
   ],
   "source": [
    "# Decoder last output \n",
    "G.eval()\n",
    "decoder_last_input_batched = decoder_last_input.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_deconv_ref = G.d4.deconv(decoder_last_input_batched)\n",
    "    out_bn_ref     = G.d4.norm(out_deconv_ref)\n",
    "    out_d4_ref     = G.d4.act(out_bn_ref)\n",
    "\n",
    "out_2d_decoder_last = out_d4_ref.squeeze(0)\n",
    "out_f_decoder_last = out_2d_decoder_last.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "assert out_f_decoder_last.ndim == 2, \"Expected 2D output [x, y]\"\n",
    "X_decoder_last, Y_decoder_last = out_f_decoder_last.shape\n",
    "\n",
    "print(\"===== DECODER LAST OUTPUT =====\")\n",
    "print(f\"Shape      : ({X_decoder_last}, {Y_decoder_last})\")\n",
    "print(f\"Total vals : {X_decoder_last * Y_decoder_last}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "503f1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs:\n",
      "  HEX : encoder_output_d5_format.mem\n",
      "  RAW : encoder_output_d5_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n"
     ]
    }
   ],
   "source": [
    "# ---- QUANTIZE ----\n",
    "out_q_all = float_to_q(\n",
    "    out_f_all,\n",
    "    frac_bits=FRAC_BITS,\n",
    "    int_bits=INT_BITS,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "\n",
    "mem_name_all_hex = f\"encoder_output_d{DATA_MODE}_format.mem\"\n",
    "mem_name_all_raw = f\"encoder_output_d{DATA_MODE}_raw.mem\"\n",
    "\n",
    "mem_path_all_hex = os.path.join(output_path, mem_name_all_hex)\n",
    "mem_path_all_raw = os.path.join(output_path, mem_name_all_raw)\n",
    "\n",
    "with open(mem_path_all_hex, \"w\") as f_hex, open(mem_path_all_raw, \"w\") as f_raw:\n",
    "    for x in range(X_all):\n",
    "        for y in range(Y_all): \n",
    "            v = int(out_q_all[x, y])\n",
    "\n",
    "            # HEX (two's complement, 32-bit)\n",
    "            f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "\n",
    "            # RAW signed decimal\n",
    "            f_raw.write(f\"{v}\\n\")\n",
    "\n",
    "print(\"Saved outputs:\")\n",
    "print(f\"  HEX : {mem_name_all_hex}\")\n",
    "print(f\"  RAW : {mem_name_all_raw}\")\n",
    "print(f\"  Shape: ({X_all}, {Y_all}), total entries = {X_all * Y_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e88070a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs:\n",
      "  HEX : decoder_last_output_d5_format.mem\n",
      "  RAW : decoder_last_output_d5_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n"
     ]
    }
   ],
   "source": [
    "out_q_decoder_last = float_to_q(\n",
    "    out_f_decoder_last,\n",
    "    frac_bits=FRAC_BITS,\n",
    "    int_bits=INT_BITS,\n",
    "    dtype=DTYPE\n",
    ")\n",
    "\n",
    "mem_name_decoder_last_hex = f\"decoder_last_output_d{DATA_MODE}_format.mem\"\n",
    "mem_name_decoder_last_raw = f\"decoder_last_output_d{DATA_MODE}_raw.mem\"\n",
    "\n",
    "mem_path_decoder_last_hex = os.path.join(output_path, mem_name_decoder_last_hex)\n",
    "mem_path_decoder_last_raw = os.path.join(output_path, mem_name_decoder_last_raw)\n",
    "\n",
    "with open(mem_path_decoder_last_hex, \"w\") as f_hex, open(mem_path_decoder_last_raw, \"w\") as f_raw:\n",
    "    for y in range(Y_decoder_last):\n",
    "        for x in range(X_decoder_last):\n",
    "            v = int(out_q_decoder_last[x, y])\n",
    "\n",
    "            # HEX (two's complement, 32-bit)\n",
    "            f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "\n",
    "            # RAW signed decimal\n",
    "            f_raw.write(f\"{v}\\n\")\n",
    "\n",
    "print(\"Saved outputs:\")\n",
    "print(f\"  HEX : {mem_name_decoder_last_hex}\")\n",
    "print(f\"  RAW : {mem_name_decoder_last_raw}\")\n",
    "print(f\"  Shape: ({X_decoder_last}, {Y_decoder_last}), total entries = {X_decoder_last * Y_decoder_last}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df91d7",
   "metadata": {},
   "source": [
    "# Group Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d5ba91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automated_output_export(G, seeds, base_data_path):\n",
    "    \"\"\"\n",
    "    Iterates through a list of seeds, generates tensors, and exports them.\n",
    "    \"\"\"\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n--- Processing Seed: {seed} ---\")\n",
    "        \n",
    "        # 1. Set Seeds for Reproducibility\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        data_path = os.path.join(base_data_path, f\"sample_output_{seed}/\")\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "        # 3. Generate Tensors\n",
    "        # Note: These are re-generated per seed to ensure different random values\n",
    "        tensors_to_process = [\n",
    "            (\"decoder_last_input\", torch.randn(64, 256, device=device), False) # x->y\n",
    "        ]\n",
    "\n",
    "        # Decoder last output \n",
    "        for name, tensor, y_first in tensors_to_process:\n",
    "            G.eval()\n",
    "            tensor_batched = tensor.unsqueeze(0)\n",
    "\n",
    "            # Decoder output\n",
    "            with torch.no_grad():\n",
    "                out_deconv_ref = G.d4.deconv(tensor_batched)\n",
    "                out_bn_ref     = G.d4.norm(out_deconv_ref)\n",
    "                out_d4_ref     = G.d4.act(out_bn_ref)\n",
    "\n",
    "            out_2d_decoder_last = out_d4_ref.squeeze(0)\n",
    "            out_f_d4 = out_2d_decoder_last.detach().cpu().numpy().astype(np.float32)\n",
    "            X_d4, Y_d4 = out_f_d4.shape\n",
    "\n",
    "            # Decoder and out output\n",
    "            with torch.no_grad():\n",
    "                out_deconv_ref = G.d4.deconv(tensor_batched)\n",
    "                out_bn_ref     = G.d4.norm(out_deconv_ref)\n",
    "                out_d4_ref     = G.d4.act(out_bn_ref)\n",
    "                out_out_ref        = G.out(out_d4_ref)\n",
    "\n",
    "            out_2d_out = out_out_ref.squeeze(0)\n",
    "            out_f_out = out_2d_out.detach().cpu().numpy().astype(np.float32)\n",
    "            X_out, Y_out = out_f_out.shape\n",
    "            \n",
    "            # Convert\n",
    "            out_q_d4 = float_to_q(\n",
    "                out_f_d4,\n",
    "                frac_bits=FRAC_BITS,\n",
    "                int_bits=INT_BITS,\n",
    "                dtype=DTYPE\n",
    "            )\n",
    "\n",
    "            out_q_out = float_to_q(\n",
    "                out_f_out,\n",
    "                frac_bits=FRAC_BITS,\n",
    "                int_bits=INT_BITS,\n",
    "                dtype=DTYPE\n",
    "            )\n",
    "\n",
    "            mem_name_decoder_last_hex = f\"decoder_last_output_d{DATA_MODE}_{seed}_format.mem\"\n",
    "            mem_name_decoder_last_raw = f\"decoder_last_output_d{DATA_MODE}_{seed}_raw.mem\"\n",
    "            mem_name_out_hex = f\"out_output_d{DATA_MODE}_{seed}_format.mem\"\n",
    "            mem_name_out_raw = f\"out_output_d{DATA_MODE}_{seed}_raw.mem\"\n",
    "\n",
    "            mem_path_decoder_last_hex = os.path.join(data_path, mem_name_decoder_last_hex)\n",
    "            mem_path_decoder_last_raw = os.path.join(data_path, mem_name_decoder_last_raw)\n",
    "            mem_path_out_hex = os.path.join(data_path, mem_name_out_hex)\n",
    "            mem_path_out_raw = os.path.join(data_path, mem_name_out_raw)\n",
    "\n",
    "            with open(mem_path_decoder_last_hex, \"w\") as f_hex, open(mem_path_decoder_last_raw, \"w\") as f_raw:\n",
    "                for y in range(Y_d4):\n",
    "                    for x in range(X_d4):\n",
    "                        v = int(out_f_d4[x, y])\n",
    "\n",
    "                        # HEX (two's complement, 32-bit)\n",
    "                        f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "\n",
    "                        # RAW signed decimal\n",
    "                        f_raw.write(f\"{v}\\n\")\n",
    "\n",
    "            print(\"Saved outputs:\")\n",
    "            print(f\"  HEX : {mem_path_decoder_last_hex}\")\n",
    "            print(f\"  RAW : {mem_path_decoder_last_raw}\")\n",
    "            print(f\"  Shape: ({X_d4}, {Y_d4}), total entries = {X_d4 * Y_d4}\")\n",
    "\n",
    "            with open(mem_path_out_hex, \"w\") as f_hex, open(mem_path_out_raw, \"w\") as f_raw:\n",
    "                for x in range(X_out):\n",
    "                    for y in range(Y_out):  \n",
    "                        v = int(out_f_out[x, y])\n",
    "\n",
    "                        # HEX (two's complement, 32-bit)\n",
    "                        f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "\n",
    "                        # RAW signed decimal\n",
    "                        f_raw.write(f\"{v}\\n\")\n",
    "            \n",
    "            print(\"Saved outputs:\")\n",
    "            print(f\"  HEX : {mem_path_out_hex}\")\n",
    "            print(f\"  RAW : {mem_path_out_raw}\")\n",
    "            print(f\"  Shape: ({X_out}, {Y_out}), total entries = {X_out * Y_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "941b813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Seed: 1234 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_1234/decoder_last_output_d5_1234_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_1234/decoder_last_output_d5_1234_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_1234/out_output_d5_1234_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_1234/out_output_d5_1234_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 420 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_420/decoder_last_output_d5_420_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_420/decoder_last_output_d5_420_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_420/out_output_d5_420_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_420/out_output_d5_420_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 67 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_67/decoder_last_output_d5_67_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_67/decoder_last_output_d5_67_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_67/out_output_d5_67_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_67/out_output_d5_67_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 69 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_69/decoder_last_output_d5_69_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_69/decoder_last_output_d5_69_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_69/out_output_d5_69_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_69/out_output_d5_69_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 13523100 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13523100/decoder_last_output_d5_13523100_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13523100/decoder_last_output_d5_13523100_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13523100/out_output_d5_13523100_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13523100/out_output_d5_13523100_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 13223051 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223051/decoder_last_output_d5_13223051_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223051/decoder_last_output_d5_13223051_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223051/out_output_d5_13223051_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223051/out_output_d5_13223051_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 13223075 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223075/decoder_last_output_d5_13223075_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223075/decoder_last_output_d5_13223075_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223075/out_output_d5_13223075_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_13223075/out_output_d5_13223075_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 42 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_42/decoder_last_output_d5_42_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_42/decoder_last_output_d5_42_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_42/out_output_d5_42_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_42/out_output_d5_42_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 21 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_21/decoder_last_output_d5_21_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_21/decoder_last_output_d5_21_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_21/out_output_d5_21_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_21/out_output_d5_21_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n",
      "\n",
      "--- Processing Seed: 20 ---\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_20/decoder_last_output_d5_20_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_20/decoder_last_output_d5_20_raw.mem\n",
      "  Shape: (16, 512), total entries = 8192\n",
      "Saved outputs:\n",
      "  HEX : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_20/out_output_d5_20_format.mem\n",
      "  RAW : c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\sample_output_Q9.14_10\\sample_output_20/out_output_d5_20_raw.mem\n",
      "  Shape: (1, 512), total entries = 512\n"
     ]
    }
   ],
   "source": [
    "seed_arr = [1234, 420, 67, 69, 13523100, 13223051, 13223075, 42, 21, 20]\n",
    "group_output_path = os.path.abspath(f\"../models/sample_output_{TYPE}_{len(seed_arr)}/\")\n",
    "os.makedirs(group_output_path, exist_ok=True)\n",
    "\n",
    "run_automated_output_export(G, seed_arr, group_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
