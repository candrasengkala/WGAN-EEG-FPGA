{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566e83bb",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466b6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679df83",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4325993",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"local\" # or \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc873f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\data\\eeg_denoise_net\n",
      "EEG shape: (4514, 512)\n",
      "EOG shape: (3400, 512)\n",
      "EMG shape: (5598, 512)\n"
     ]
    }
   ],
   "source": [
    "if ENV == \"kaggle\":\n",
    "    EEG = np.load(\"/kaggle/input/eeg-denoise-net/EEG_all_epochs.npy\")\n",
    "    EOG = np.load(\"/kaggle/input/eeg-denoise-net/EOG_all_epochs.npy\")\n",
    "    EMG = np.load(\"/kaggle/input/eeg-denoise-net/EMG_all_epochs.npy\")\n",
    "else:\n",
    "    data_path = os.path.abspath(\"../../data/eeg_denoise_net/\")\n",
    "    print(data_path)\n",
    "    \n",
    "    EEG = np.load(os.path.join(data_path, \"EEG_all_epochs.npy\"))\n",
    "    EOG = np.load(os.path.join(data_path, \"EOG_all_epochs.npy\"))\n",
    "    EMG = np.load(os.path.join(data_path, \"EMG_all_epochs.npy\"))\n",
    "\n",
    "print(\"EEG shape:\", EEG.shape)\n",
    "print(\"EOG shape:\", EOG.shape)\n",
    "print(\"EMG shape:\", EMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be336d",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50caf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Root Mean Square (RMS) of a 1D signal.\n",
    "    Implements Formula (3).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return np.sqrt(np.mean(x ** 2))\n",
    "\n",
    "def snr_db(clean: np.ndarray, noise: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute SNR in decibels.\n",
    "    Implements Formula (2).\n",
    "    \"\"\"\n",
    "    return 10 * np.log10(rms(clean) / rms(noise))\n",
    "\n",
    "def compute_lambda(clean: np.ndarray, noise: np.ndarray, target_snr_db: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute lambda such that the mixed signal has the desired SNR (in dB).\n",
    "    \"\"\"\n",
    "    return rms(clean) / rms(noise) * 10 ** (-target_snr_db / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc6de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_signals(clean: np.ndarray, noise: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    Mix clean signal with noise at a target SNR (dB).\n",
    "    \n",
    "    Returns:\n",
    "        mixed_signal\n",
    "        lambda_used\n",
    "    \"\"\"\n",
    "    lam = compute_lambda(clean, noise, target_snr_db)\n",
    "    mixed = clean + lam * noise\n",
    "    return mixed, lam\n",
    "\n",
    "def noisy_eeg_eog(eeg: np.ndarray, eog: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    EEG contaminated by ocular artifacts (EOG).\n",
    "    \"\"\"\n",
    "    return mix_signals(eeg, eog, target_snr_db)\n",
    "\n",
    "def noisy_eeg_emg(eeg: np.ndarray, emg: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    EEG contaminated by myogenic artifacts (EMG).\n",
    "    \"\"\"\n",
    "    return mix_signals(eeg, emg, target_snr_db)\n",
    "\n",
    "def noisy_eeg_eog_emg(\n",
    "    eeg: np.ndarray,\n",
    "    eog: np.ndarray,\n",
    "    emg: np.ndarray,\n",
    "    target_snr_db: float,\n",
    "    eog_weight: float = 1.0,\n",
    "    emg_weight: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    EEG contaminated by both ocular (EOG) and myogenic (EMG) artifacts.\n",
    "    \n",
    "    eog_weight / emg_weight allow control of relative artifact dominance.\n",
    "    \"\"\"\n",
    "    combined_noise = eog_weight * eog + emg_weight * emg\n",
    "    return mix_signals(eeg, combined_noise, target_snr_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1d524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy_sample(\n",
    "    noisy_signal,\n",
    "    eeg_idx,\n",
    "    eog_idx=None,\n",
    "    emg_idx=None,\n",
    "    snr_db=None,\n",
    "    lambda_used=None\n",
    "):\n",
    "    return {\n",
    "        \"noisy\": noisy_signal,      # np.ndarray (512,)\n",
    "        \"eeg_idx\": eeg_idx,         # int\n",
    "        \"eog_idx\": eog_idx,         # int or None\n",
    "        \"emg_idx\": emg_idx,         # int or None\n",
    "        \"snr_db\": snr_db,           # float\n",
    "        \"lambda\": lambda_used       # float\n",
    "    }\n",
    "\n",
    "def sample_snr_uniform(low, high, rng):\n",
    "    return rng.uniform(low, high)\n",
    "\n",
    "def fixed_snr_list(snrs, rng):\n",
    "    return rng.choice(snrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e522c04",
   "metadata": {},
   "source": [
    "# Mixers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c01c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_eeg_eog_paper(\n",
    "    EEG,\n",
    "    EOG,\n",
    "    seed=42,\n",
    "    mode=\"random\"  # \"exhaustive\" | \"random\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    eeg_train_idx = np.arange(3000)\n",
    "    eeg_test_idx  = np.arange(3000, 3400)\n",
    "\n",
    "    snr_grid = np.array([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    if mode == \"exhaustive\":\n",
    "        # ---- training: 10x uniform SNR ----\n",
    "        for _ in range(10):\n",
    "            perm = rng.permutation(eeg_train_idx)\n",
    "            for i in perm:\n",
    "                snr = sample_snr_uniform(-7, 2, rng)\n",
    "                noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "                train_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=i,\n",
    "                        eog_idx=i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # ---- testing: fixed SNR grid ----\n",
    "        for snr in snr_grid:\n",
    "            for i in eeg_test_idx:\n",
    "                noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "                test_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=i,\n",
    "                        eog_idx=i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    elif mode == \"random\":\n",
    "        # ---- training: single pass, random SNR from grid ----\n",
    "        for i in eeg_train_idx:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "            train_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=i,\n",
    "                    eog_idx=i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ---- testing ----\n",
    "        for i in eeg_test_idx:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "            test_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=i,\n",
    "                    eog_idx=i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'exhaustive' or 'random'\")\n",
    "\n",
    "    return train_samples, test_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed036404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_eeg_emg_paper(\n",
    "    EEG,\n",
    "    EMG,\n",
    "    seed=42,\n",
    "    mode=\"random\"  # \"exhaustive\" | \"random\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    eeg_indices = rng.choice(len(EEG), size=len(EMG), replace=True)\n",
    "    emg_indices = np.arange(len(EMG))\n",
    "\n",
    "    pairs = list(zip(eeg_indices, emg_indices))\n",
    "    rng.shuffle(pairs)\n",
    "\n",
    "    train_pairs = pairs[:5000]\n",
    "    test_pairs  = pairs[5000:5598]\n",
    "\n",
    "    snr_grid = np.array([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    if mode == \"exhaustive\":\n",
    "        # ---- training: 10x ----\n",
    "        for _ in range(10):\n",
    "            for eeg_i, emg_i in train_pairs:\n",
    "                snr = sample_snr_uniform(-7, 2, rng)\n",
    "                noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "                train_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=eeg_i,\n",
    "                        emg_idx=emg_i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # ---- testing: fixed grid ----\n",
    "        for snr in snr_grid:\n",
    "            for eeg_i, emg_i in test_pairs:\n",
    "                noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "                test_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=eeg_i,\n",
    "                        emg_idx=emg_i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    elif mode == \"random\":\n",
    "        # ---- training ----\n",
    "        for eeg_i, emg_i in train_pairs:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "            train_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=eeg_i,\n",
    "                    emg_idx=emg_i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ---- testing ----\n",
    "        for eeg_i, emg_i in test_pairs:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "            test_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=eeg_i,\n",
    "                    emg_idx=emg_i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'exhaustive' or 'random'\")\n",
    "\n",
    "    return train_samples, test_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5d853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_custom(\n",
    "    EEG,\n",
    "    EOG=None,\n",
    "    EMG=None,\n",
    "    n_train=10000,\n",
    "    n_test=2000,\n",
    "    snr_range=(-7, 2),\n",
    "    seed=42,\n",
    "    eog_weight=1.0,\n",
    "    emg_weight=1.0\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    def make_one():\n",
    "        eeg_i = rng.integers(len(EEG))\n",
    "        snr = rng.uniform(*snr_range)\n",
    "\n",
    "        eog_i = None\n",
    "        emg_i = None\n",
    "\n",
    "        if EOG is not None and EMG is not None:\n",
    "            eog_i = rng.integers(len(EOG))\n",
    "            emg_i = rng.integers(len(EMG))\n",
    "            noisy, lam = noisy_eeg_eog_emg(\n",
    "                EEG[eeg_i],\n",
    "                EOG[eog_i],\n",
    "                EMG[emg_i],\n",
    "                snr,\n",
    "                eog_weight=eog_weight,\n",
    "                emg_weight=emg_weight\n",
    "            )\n",
    "\n",
    "        elif EOG is not None:\n",
    "            eog_i = rng.integers(len(EOG))\n",
    "            noisy, lam = noisy_eeg_eog(EEG[eeg_i], EOG[eog_i], snr)\n",
    "\n",
    "        elif EMG is not None:\n",
    "            emg_i = rng.integers(len(EMG))\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"At least one of EOG or EMG must be provided.\")\n",
    "\n",
    "        return make_noisy_sample(\n",
    "            noisy,\n",
    "            eeg_idx=eeg_i,\n",
    "            eog_idx=eog_i,\n",
    "            emg_idx=emg_i,\n",
    "            snr_db=snr,\n",
    "            lambda_used=lam\n",
    "        )\n",
    "\n",
    "    for _ in range(n_train + n_test):\n",
    "        samples.append(make_one())\n",
    "\n",
    "    return samples[:n_train], samples[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb189eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_noisy_sample(sample, EEG):\n",
    "    \"\"\"\n",
    "    Normalize one noisy EEG sample according to EEGdenoiseNet protocol.\n",
    "    \n",
    "    Args:\n",
    "        sample: dict produced by make_noisy_sample\n",
    "        EEG: clean EEG array (for ground truth lookup)\n",
    "    \n",
    "    Returns:\n",
    "        normalized_sample (new dict)\n",
    "    \"\"\"\n",
    "    y = sample[\"noisy\"]\n",
    "    x = EEG[sample[\"eeg_idx\"]]\n",
    "\n",
    "    sigma_y = np.std(y)\n",
    "    if sigma_y == 0:\n",
    "        raise ValueError(\"Standard deviation of noisy signal is zero.\")\n",
    "\n",
    "    normalized_sample = sample.copy()\n",
    "    normalized_sample.update({\n",
    "        \"noisy_norm\": y / sigma_y,     # ŷ\n",
    "        \"clean_norm\": x / sigma_y,     # x̂\n",
    "        \"sigma_y\": sigma_y             # stored for rescaling later\n",
    "    })\n",
    "\n",
    "    return normalized_sample\n",
    "\n",
    "def normalize_dataset(samples, EEG):\n",
    "    \"\"\"\n",
    "    Normalize a list of noisy EEG samples.\n",
    "    \n",
    "    Args:\n",
    "        samples: list of noisy sample dicts\n",
    "        EEG: clean EEG array\n",
    "    \n",
    "    Returns:\n",
    "        list of normalized sample dicts\n",
    "    \"\"\"\n",
    "    return [normalize_noisy_sample(s, EEG) for s in samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ca66e",
   "metadata": {},
   "source": [
    "# Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547a037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = EEG + EOG Paper\n",
    "# 2 = EEG + EMG Paper\n",
    "# 3 = Custom EEG + EOG\n",
    "# 4 = Custom EEG + EMG\n",
    "# else Custom EEG + EOG + EMG\n",
    "DATA_MODE = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e776cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_MODE == 1: # EEG + EOG Paper\n",
    "    # --- generate noisy datasets (raw, unnormalized) ---\n",
    "    train_samples, test_samples = mix_eeg_eog_paper(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # --- normalize according to EEGdenoiseNet protocol ---\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 2: # EEG + EMG Paper\n",
    "    # --- generate noisy datasets (raw, unnormalized) ---\n",
    "    train_samples, test_samples = mix_eeg_emg_paper(\n",
    "        EEG=EEG,\n",
    "        EMG=EMG,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # --- normalize ---\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 3:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 4:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EMG=EMG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "\n",
    "else:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        EMG=EMG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42,\n",
    "        eog_weight=1.0,\n",
    "        emg_weight=1.0\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f995e8f",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f29c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=15, s=2, p=7, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'lrelu' or 'relu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DeconvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvTranspose1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=4, s=2, p=1, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'relu' or 'lrelu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.deconv(x)))\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block: (Conv -> BN -> ReLU) x2 + skip\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, k=7, p=3, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n1 = nn.BatchNorm1d(ch)\n",
    "        self.c2 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n2 = nn.BatchNorm1d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.n1(self.c1(x)))\n",
    "        h = self.n2(self.c2(h))\n",
    "        return F.relu(x + h)\n",
    "    \n",
    "class MultiScaleResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale residual block: parallel conv branches (k=3,5,7) then fuse.\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=3, padding=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=5, padding=2, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b7 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=7, padding=3, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.b3(x) + self.b5(x) + self.b7(x)\n",
    "        h = self.fuse(h)\n",
    "        return F.relu(x + h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Generator (U-Net-ish + Res bottleneck)\n",
    "class GeneratorCNNWGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN U-Net-ish generator for EEG denoising (WGAN).\n",
    "    Input : (B, 1, 512) noisy_norm\n",
    "    Output: (B, 1, 512) clean_norm_hat\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = ConvBlock1D(1, base_ch,       k=16, s=2, p=7, bias=bias, act=\"lrelu\")      # 512 -> 256\n",
    "        self.e2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.e3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.e4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "\n",
    "        # Bottleneck\n",
    "        bn_ch = base_ch * 8\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            ResBlock1D(bn_ch, k=7, p=3, bias=bias) for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        # Decoder (concat doubles channels)\n",
    "        self.d1 = DeconvBlock1D(bn_ch, base_ch*4,   k=4, s=2, p=1, bias=bias, act=\"relu\")     # 32 -> 64\n",
    "        self.d2 = DeconvBlock1D(base_ch*8, base_ch*2, k=4, s=2, p=1,bias=bias, act=\"relu\")   # 64 -> 128\n",
    "        self.d3 = DeconvBlock1D(base_ch*4, base_ch,   k=4, s=2, p=1, bias=bias, act=\"relu\")   # 128 -> 256\n",
    "        self.d4 = DeconvBlock1D(base_ch*2, base_ch//2, k=4, s=2, p=1, bias=bias, act=\"relu\")  # 256 -> 512\n",
    "\n",
    "        # Head (linear output recommended for normalized signals)\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, kernel_size=7, stride=1, padding=3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        # Encoder\n",
    "        s1 = self.e1(y)   # (B, base, 256)\n",
    "        s2 = self.e2(s1)  # (B, 2b, 128)\n",
    "        s3 = self.e3(s2)  # (B, 4b, 64)\n",
    "        s4 = self.e4(s3)  # (B, 8b, 32)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(s4)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        d1 = self.d1(b)                  # (B, 4b, 64)\n",
    "        d1 = torch.cat([d1, s3], dim=1)  # (B, 8b, 64)\n",
    "\n",
    "        d2 = self.d2(d1)                 # (B, 2b, 128)\n",
    "        d2 = torch.cat([d2, s2], dim=1)  # (B, 4b, 128)\n",
    "\n",
    "        d3 = self.d3(d2)                 # (B, b, 256)\n",
    "        d3 = torch.cat([d3, s1], dim=1)  # (B, 2b, 256)\n",
    "\n",
    "        d4 = self.d4(d3)                 # (B, b/2, 512)\n",
    "\n",
    "        return self.out(d4)              # (B, 1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef71ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Critic (shared by CNN/ResCNN)\n",
    "class CriticPatch1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional PatchGAN critic for WGAN:\n",
    "      D(y, x) -> patch scores\n",
    "    y,x: (B,1,512)\n",
    "    output: (B,1,32)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(2, base_ch, kernel_size=16, stride=2, padding=7, bias=bias)  # 512 -> 256\n",
    "        self.c2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.c3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.c4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "        self.out = nn.Conv1d(base_ch*8, 1, kernel_size=7, stride=1, padding=3, bias=bias)   # 32 -> 32\n",
    "\n",
    "    def forward(self, y, x):\n",
    "        h = torch.cat([y, x], dim=1)  # (B,2,512)\n",
    "        h = F.leaky_relu(self.c1(h), 0.2, inplace=True)\n",
    "        h = self.c2(h)\n",
    "        h = self.c3(h)\n",
    "        h = self.c4(h)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ea6ed",
   "metadata": {},
   "source": [
    "# Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b10b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2bbd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\n",
      "G: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\\cnn_G_20260113_074150.pth\n",
      "D: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\\cnn_D_20260113_074150.pth\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(f\"../models/main3_d{DATA_MODE}_{\"b\" if BIAS else \"nb\"}/\")\n",
    "print(data_path)\n",
    "\n",
    "pattern = re.compile(r\"^cnn_([DG])_\\d{8}_\\d{6}\\.pth$\")\n",
    "\n",
    "cnn_G_path = None\n",
    "cnn_D_path = None\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "    m = pattern.match(f)\n",
    "    if m:\n",
    "        full = os.path.join(data_path, f)\n",
    "        if m.group(1) == \"G\":\n",
    "            cnn_G_path = full\n",
    "        else:\n",
    "            cnn_D_path = full\n",
    "\n",
    "print(\"G:\", cnn_G_path)\n",
    "print(\"D:\", cnn_D_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e795bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorCNNWGAN(\n",
      "  (e1): ConvBlock1D(\n",
      "    (conv): Conv1d(1, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d1): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d2): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d3): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(128, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d4): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(64, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "CriticPatch1D(\n",
      "  (c1): Conv1d(2, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "  (c2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(256, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_26992\\2181062752.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_26992\\2181062752.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = GeneratorCNNWGAN(bias=BIAS).to(device)\n",
    "D = CriticPatch1D(bias=BIAS).to(device)\n",
    "\n",
    "G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
    "D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n",
    "\n",
    "print(G.eval())\n",
    "print(D.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97fd7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> GeneratorCNNWGAN\n",
      "e1 -> ConvBlock1D\n",
      "e1.conv -> Conv1d\n",
      "e1.norm -> BatchNorm1d\n",
      "e1.act -> LeakyReLU\n",
      "e2 -> ConvBlock1D\n",
      "e2.conv -> Conv1d\n",
      "e2.norm -> BatchNorm1d\n",
      "e2.act -> LeakyReLU\n",
      "e3 -> ConvBlock1D\n",
      "e3.conv -> Conv1d\n",
      "e3.norm -> BatchNorm1d\n",
      "e3.act -> LeakyReLU\n",
      "e4 -> ConvBlock1D\n",
      "e4.conv -> Conv1d\n",
      "e4.norm -> BatchNorm1d\n",
      "e4.act -> LeakyReLU\n",
      "bottleneck -> Sequential\n",
      "bottleneck.0 -> ResBlock1D\n",
      "bottleneck.0.c1 -> Conv1d\n",
      "bottleneck.0.n1 -> BatchNorm1d\n",
      "bottleneck.0.c2 -> Conv1d\n",
      "bottleneck.0.n2 -> BatchNorm1d\n",
      "bottleneck.1 -> ResBlock1D\n",
      "bottleneck.1.c1 -> Conv1d\n",
      "bottleneck.1.n1 -> BatchNorm1d\n",
      "bottleneck.1.c2 -> Conv1d\n",
      "bottleneck.1.n2 -> BatchNorm1d\n",
      "bottleneck.2 -> ResBlock1D\n",
      "bottleneck.2.c1 -> Conv1d\n",
      "bottleneck.2.n1 -> BatchNorm1d\n",
      "bottleneck.2.c2 -> Conv1d\n",
      "bottleneck.2.n2 -> BatchNorm1d\n",
      "bottleneck.3 -> ResBlock1D\n",
      "bottleneck.3.c1 -> Conv1d\n",
      "bottleneck.3.n1 -> BatchNorm1d\n",
      "bottleneck.3.c2 -> Conv1d\n",
      "bottleneck.3.n2 -> BatchNorm1d\n",
      "d1 -> DeconvBlock1D\n",
      "d1.deconv -> ConvTranspose1d\n",
      "d1.norm -> BatchNorm1d\n",
      "d1.act -> ReLU\n",
      "d2 -> DeconvBlock1D\n",
      "d2.deconv -> ConvTranspose1d\n",
      "d2.norm -> BatchNorm1d\n",
      "d2.act -> ReLU\n",
      "d3 -> DeconvBlock1D\n",
      "d3.deconv -> ConvTranspose1d\n",
      "d3.norm -> BatchNorm1d\n",
      "d3.act -> ReLU\n",
      "d4 -> DeconvBlock1D\n",
      "d4.deconv -> ConvTranspose1d\n",
      "d4.norm -> BatchNorm1d\n",
      "d4.act -> ReLU\n",
      "out -> Conv1d\n",
      "\n",
      "================================================================================\n",
      "\n",
      " -> CriticPatch1D\n",
      "c1 -> Conv1d\n",
      "c2 -> ConvBlock1D\n",
      "c2.conv -> Conv1d\n",
      "c2.norm -> BatchNorm1d\n",
      "c2.act -> LeakyReLU\n",
      "c3 -> ConvBlock1D\n",
      "c3.conv -> Conv1d\n",
      "c3.norm -> BatchNorm1d\n",
      "c3.act -> LeakyReLU\n",
      "c4 -> ConvBlock1D\n",
      "c4.conv -> Conv1d\n",
      "c4.norm -> BatchNorm1d\n",
      "c4.act -> LeakyReLU\n",
      "out -> Conv1d\n"
     ]
    }
   ],
   "source": [
    "for name, module in G.named_modules():\n",
    "    print(name, \"->\", module.__class__.__name__)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, module in D.named_modules():\n",
    "    print(name, \"->\", module.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4663f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1.conv.weight torch.Size([32, 1, 16]) True\n",
      "e1.conv.bias torch.Size([32]) True\n",
      "e1.norm.weight torch.Size([32]) True\n",
      "e1.norm.bias torch.Size([32]) True\n",
      "e2.conv.weight torch.Size([64, 32, 16]) True\n",
      "e2.conv.bias torch.Size([64]) True\n",
      "e2.norm.weight torch.Size([64]) True\n",
      "e2.norm.bias torch.Size([64]) True\n",
      "e3.conv.weight torch.Size([128, 64, 16]) True\n",
      "e3.conv.bias torch.Size([128]) True\n",
      "e3.norm.weight torch.Size([128]) True\n",
      "e3.norm.bias torch.Size([128]) True\n",
      "e4.conv.weight torch.Size([256, 128, 16]) True\n",
      "e4.conv.bias torch.Size([256]) True\n",
      "e4.norm.weight torch.Size([256]) True\n",
      "e4.norm.bias torch.Size([256]) True\n",
      "bottleneck.0.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.0.c1.bias torch.Size([256]) True\n",
      "bottleneck.0.n1.weight torch.Size([256]) True\n",
      "bottleneck.0.n1.bias torch.Size([256]) True\n",
      "bottleneck.0.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.0.c2.bias torch.Size([256]) True\n",
      "bottleneck.0.n2.weight torch.Size([256]) True\n",
      "bottleneck.0.n2.bias torch.Size([256]) True\n",
      "bottleneck.1.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.1.c1.bias torch.Size([256]) True\n",
      "bottleneck.1.n1.weight torch.Size([256]) True\n",
      "bottleneck.1.n1.bias torch.Size([256]) True\n",
      "bottleneck.1.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.1.c2.bias torch.Size([256]) True\n",
      "bottleneck.1.n2.weight torch.Size([256]) True\n",
      "bottleneck.1.n2.bias torch.Size([256]) True\n",
      "bottleneck.2.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.2.c1.bias torch.Size([256]) True\n",
      "bottleneck.2.n1.weight torch.Size([256]) True\n",
      "bottleneck.2.n1.bias torch.Size([256]) True\n",
      "bottleneck.2.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.2.c2.bias torch.Size([256]) True\n",
      "bottleneck.2.n2.weight torch.Size([256]) True\n",
      "bottleneck.2.n2.bias torch.Size([256]) True\n",
      "bottleneck.3.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.3.c1.bias torch.Size([256]) True\n",
      "bottleneck.3.n1.weight torch.Size([256]) True\n",
      "bottleneck.3.n1.bias torch.Size([256]) True\n",
      "bottleneck.3.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.3.c2.bias torch.Size([256]) True\n",
      "bottleneck.3.n2.weight torch.Size([256]) True\n",
      "bottleneck.3.n2.bias torch.Size([256]) True\n",
      "d1.deconv.weight torch.Size([256, 128, 4]) True\n",
      "d1.deconv.bias torch.Size([128]) True\n",
      "d1.norm.weight torch.Size([128]) True\n",
      "d1.norm.bias torch.Size([128]) True\n",
      "d2.deconv.weight torch.Size([256, 64, 4]) True\n",
      "d2.deconv.bias torch.Size([64]) True\n",
      "d2.norm.weight torch.Size([64]) True\n",
      "d2.norm.bias torch.Size([64]) True\n",
      "d3.deconv.weight torch.Size([128, 32, 4]) True\n",
      "d3.deconv.bias torch.Size([32]) True\n",
      "d3.norm.weight torch.Size([32]) True\n",
      "d3.norm.bias torch.Size([32]) True\n",
      "d4.deconv.weight torch.Size([64, 16, 4]) True\n",
      "d4.deconv.bias torch.Size([16]) True\n",
      "d4.norm.weight torch.Size([16]) True\n",
      "d4.norm.bias torch.Size([16]) True\n",
      "out.weight torch.Size([1, 16, 7]) True\n",
      "out.bias torch.Size([1]) True\n",
      "\n",
      "================================================================================\n",
      "\n",
      "c1.weight torch.Size([32, 2, 16]) True\n",
      "c1.bias torch.Size([32]) True\n",
      "c2.conv.weight torch.Size([64, 32, 16]) True\n",
      "c2.conv.bias torch.Size([64]) True\n",
      "c2.norm.weight torch.Size([64]) True\n",
      "c2.norm.bias torch.Size([64]) True\n",
      "c3.conv.weight torch.Size([128, 64, 16]) True\n",
      "c3.conv.bias torch.Size([128]) True\n",
      "c3.norm.weight torch.Size([128]) True\n",
      "c3.norm.bias torch.Size([128]) True\n",
      "c4.conv.weight torch.Size([256, 128, 16]) True\n",
      "c4.conv.bias torch.Size([256]) True\n",
      "c4.norm.weight torch.Size([256]) True\n",
      "c4.norm.bias torch.Size([256]) True\n",
      "out.weight torch.Size([1, 256, 7]) True\n",
      "out.bias torch.Size([1]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in G.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, param in D.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "921e8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1.norm.running_mean torch.Size([32])\n",
      "e1.norm.running_var torch.Size([32])\n",
      "e1.norm.num_batches_tracked torch.Size([])\n",
      "e2.norm.running_mean torch.Size([64])\n",
      "e2.norm.running_var torch.Size([64])\n",
      "e2.norm.num_batches_tracked torch.Size([])\n",
      "e3.norm.running_mean torch.Size([128])\n",
      "e3.norm.running_var torch.Size([128])\n",
      "e3.norm.num_batches_tracked torch.Size([])\n",
      "e4.norm.running_mean torch.Size([256])\n",
      "e4.norm.running_var torch.Size([256])\n",
      "e4.norm.num_batches_tracked torch.Size([])\n",
      "bottleneck.0.n1.running_mean torch.Size([256])\n",
      "bottleneck.0.n1.running_var torch.Size([256])\n",
      "bottleneck.0.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.0.n2.running_mean torch.Size([256])\n",
      "bottleneck.0.n2.running_var torch.Size([256])\n",
      "bottleneck.0.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.1.n1.running_mean torch.Size([256])\n",
      "bottleneck.1.n1.running_var torch.Size([256])\n",
      "bottleneck.1.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.1.n2.running_mean torch.Size([256])\n",
      "bottleneck.1.n2.running_var torch.Size([256])\n",
      "bottleneck.1.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.2.n1.running_mean torch.Size([256])\n",
      "bottleneck.2.n1.running_var torch.Size([256])\n",
      "bottleneck.2.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.2.n2.running_mean torch.Size([256])\n",
      "bottleneck.2.n2.running_var torch.Size([256])\n",
      "bottleneck.2.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.3.n1.running_mean torch.Size([256])\n",
      "bottleneck.3.n1.running_var torch.Size([256])\n",
      "bottleneck.3.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.3.n2.running_mean torch.Size([256])\n",
      "bottleneck.3.n2.running_var torch.Size([256])\n",
      "bottleneck.3.n2.num_batches_tracked torch.Size([])\n",
      "d1.norm.running_mean torch.Size([128])\n",
      "d1.norm.running_var torch.Size([128])\n",
      "d1.norm.num_batches_tracked torch.Size([])\n",
      "d2.norm.running_mean torch.Size([64])\n",
      "d2.norm.running_var torch.Size([64])\n",
      "d2.norm.num_batches_tracked torch.Size([])\n",
      "d3.norm.running_mean torch.Size([32])\n",
      "d3.norm.running_var torch.Size([32])\n",
      "d3.norm.num_batches_tracked torch.Size([])\n",
      "d4.norm.running_mean torch.Size([16])\n",
      "d4.norm.running_var torch.Size([16])\n",
      "d4.norm.num_batches_tracked torch.Size([])\n",
      "\n",
      "================================================================================\n",
      "\n",
      "c2.norm.running_mean torch.Size([64])\n",
      "c2.norm.running_var torch.Size([64])\n",
      "c2.norm.num_batches_tracked torch.Size([])\n",
      "c3.norm.running_mean torch.Size([128])\n",
      "c3.norm.running_var torch.Size([128])\n",
      "c3.norm.num_batches_tracked torch.Size([])\n",
      "c4.norm.running_mean torch.Size([256])\n",
      "c4.norm.running_var torch.Size([256])\n",
      "c4.norm.num_batches_tracked torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for name, buf in G.named_buffers():\n",
    "    print(name, buf.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, buf in D.named_buffers():\n",
    "    print(name, buf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b761e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BN layer: e1.norm\n",
      " running_mean: torch.Size([32])\n",
      " running_var : torch.Size([32])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e2.norm\n",
      " running_mean: torch.Size([64])\n",
      " running_var : torch.Size([64])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e3.norm\n",
      " running_mean: torch.Size([128])\n",
      " running_var : torch.Size([128])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e4.norm\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.0.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.0.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.1.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.1.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.2.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.2.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.3.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.3.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d1.norm\n",
      " running_mean: torch.Size([128])\n",
      " running_var : torch.Size([128])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d2.norm\n",
      " running_mean: torch.Size([64])\n",
      " running_var : torch.Size([64])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d3.norm\n",
      " running_mean: torch.Size([32])\n",
      " running_var : torch.Size([32])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d4.norm\n",
      " running_mean: torch.Size([16])\n",
      " running_var : torch.Size([16])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n"
     ]
    }
   ],
   "source": [
    "for name, module in G.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm1d):\n",
    "        print(f\"\\nBN layer: {name}\")\n",
    "        print(\" running_mean:\", module.running_mean.shape)\n",
    "        print(\" running_var :\", module.running_var.shape)\n",
    "        print(\" momentum    :\", module.momentum)\n",
    "        print(\" eps         :\", module.eps)\n",
    "        print(\" affine      :\", module.affine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccfef0",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e1f2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrmse(x_hat, x):\n",
    "    return torch.sqrt(torch.mean((x_hat - x) ** 2)) / torch.sqrt(torch.mean(x ** 2))\n",
    "\n",
    "\n",
    "def corrcoef(x_hat, x):\n",
    "    x_hat = x_hat - x_hat.mean()\n",
    "    x = x - x.mean()\n",
    "    return torch.sum(x_hat * x) / (\n",
    "        torch.sqrt(torch.sum(x_hat ** 2)) * torch.sqrt(torch.sum(x ** 2)) + 1e-8\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fe6237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(len(test_samples_norm[0][\"noisy_norm\"]))\n",
    "\n",
    "sample = test_samples_norm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f072f6",
   "metadata": {},
   "source": [
    "## Generator Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b1166cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(sample[\"noisy_norm\"], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device) # (1, 1, T)\n",
    "x = torch.tensor(sample[\"clean_norm\"], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "G.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_hat_ref = G(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cf1d9",
   "metadata": {},
   "source": [
    "## Manual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9dacddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free(*tensors):\n",
    "    for t in tensors:\n",
    "        del t\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c725f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_transconv(\n",
    "    x,              # (N, Cin, T_in)\n",
    "    weight_value,   # (Cin, Cout, K)\n",
    "    bias_value=None,# (Cout,) or None\n",
    "    s=2,\n",
    "    p=1,\n",
    "    output_padding=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Manual ConvTranspose1d (inference / eval semantics)\n",
    "\n",
    "    Matches PyTorch nn.ConvTranspose1d:\n",
    "    - weight shape: (Cin, Cout, K)\n",
    "    \"\"\"\n",
    "\n",
    "    N, Cin, T_in = x.shape\n",
    "    Cin_w, Cout, K = weight_value.shape\n",
    "    assert Cin == Cin_w\n",
    "\n",
    "    # PyTorch output length formula\n",
    "    T_out = (T_in - 1) * s - 2 * p + K + output_padding\n",
    "\n",
    "    out = torch.zeros(\n",
    "        (N, Cout, T_out),\n",
    "        device=x.device,\n",
    "        dtype=x.dtype\n",
    "    )\n",
    "\n",
    "    for n in range(N):\n",
    "        for ci in range(Cin):\n",
    "            for ti in range(T_in):\n",
    "                base = ti * s - p\n",
    "\n",
    "                for k in range(K):\n",
    "                    t_out = base + k\n",
    "                    if 0 <= t_out < T_out:\n",
    "                        for co in range(Cout):\n",
    "                            out[n, co, t_out] += (\n",
    "                                x[n, ci, ti]\n",
    "                                * weight_value[ci, co, k]\n",
    "                            )\n",
    "\n",
    "    if bias_value is not None:\n",
    "        out += bias_value[None, :, None]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cea28958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_batchnorm1d(\n",
    "    x,              # (N, C, T)\n",
    "    running_mean,   # (C,)\n",
    "    running_var,    # (C,)\n",
    "    weight=None,    # (C,) or None\n",
    "    bias=None,      # (C,) or None\n",
    "    eps=1e-5\n",
    "):\n",
    "    N, C, T = x.shape\n",
    "\n",
    "    out = torch.zeros_like(x)\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            mean = running_mean[c]\n",
    "            var = running_var[c]\n",
    "            denom = torch.sqrt(var + eps)\n",
    "\n",
    "            for t in range(T):\n",
    "                y = (x[n, c, t] - mean) / denom\n",
    "\n",
    "                if weight is not None:\n",
    "                    y = y * weight[c]\n",
    "\n",
    "                if bias is not None:\n",
    "                    y = y + bias[c]\n",
    "\n",
    "                out[n, c, t] = y\n",
    "\n",
    "    return out\n",
    "\n",
    "def manual_batchnorm1d_fast(x, bn):\n",
    "    mean = bn.running_mean[None, :, None]\n",
    "    var = bn.running_var[None, :, None]\n",
    "\n",
    "    y = (x - mean) / torch.sqrt(var + bn.eps)\n",
    "\n",
    "    if bn.affine:\n",
    "        y = y * bn.weight[None, :, None] + bn.bias[None, :, None]\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afedb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_relu(x):\n",
    "    out = torch.zeros_like(x)\n",
    "\n",
    "    mask_pos = x >= 0\n",
    "    mask_neg = x < 0\n",
    "\n",
    "    out[mask_pos] = x[mask_pos]\n",
    "    out[mask_neg] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def manual_leaky_relu(x, negative_slope=0.2):\n",
    "    out = torch.zeros_like(x)\n",
    "\n",
    "    mask_pos = x >= 0\n",
    "    mask_neg = x < 0\n",
    "\n",
    "    out[mask_pos] = x[mask_pos]\n",
    "    out[mask_neg] = negative_slope * x[mask_neg]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06348d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_deconv_bn_1d(\n",
    "    deconv_weight,     # (Cin, Cout, K)\n",
    "    deconv_bias,       # (Cout,) or None\n",
    "    running_mean,      # (Cout,)\n",
    "    running_var,       # (Cout,)\n",
    "    bn_weight,         # (Cout,)\n",
    "    bn_bias,           # (Cout,)\n",
    "    eps\n",
    "):\n",
    "    Cin, Cout, K = deconv_weight.shape\n",
    "\n",
    "    if deconv_bias is None:\n",
    "        deconv_bias = torch.zeros(\n",
    "            Cout,\n",
    "            device=deconv_weight.device,\n",
    "            dtype=deconv_weight.dtype\n",
    "        )\n",
    "\n",
    "    # BN scale\n",
    "    scale = bn_weight / torch.sqrt(running_var + eps)  # (Cout,)\n",
    "\n",
    "    # Fuse weights (scale on Cout dimension)\n",
    "    fused_weight = deconv_weight * scale.view(1, Cout, 1)\n",
    "\n",
    "    # Fuse bias\n",
    "    fused_bias = (deconv_bias - running_mean) * scale + bn_bias\n",
    "\n",
    "    return fused_weight, fused_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f7e32e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G.training: False\n",
      "d4.training: False\n",
      "d4.deconv.training: False\n",
      "d4.norm.training: False\n",
      "d4.act.training: False\n",
      "Fused Conv vs (Conv+BN) max abs diff: 3.7915029525756836\n",
      "E1 fused max abs diff: 0.0008767843246459961\n",
      "E1 fused mean abs diff: 0.0001021545467665419\n",
      "Final RMSE: 0.00016998803766909987\n"
     ]
    }
   ],
   "source": [
    "# --- MANUAL D4 BLOCK (FUSED DECONV + BN) ---\n",
    "G.eval()\n",
    "\n",
    "print(\"G.training:\", G.training)\n",
    "print(\"d4.training:\", G.d4.training)\n",
    "print(\"d4.deconv.training:\", G.d4.deconv.training)\n",
    "print(\"d4.norm.training:\", G.d4.norm.training)\n",
    "print(\"d4.act.training:\", G.d4.act.training)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Create VALID random input for d4\n",
    "# -------------------------------------------------\n",
    "B = 1\n",
    "device = next(G.parameters()).device\n",
    "\n",
    "x = torch.randn(B, 64, 256, device=device)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) Fuse deconv + BN\n",
    "# -------------------------------------------------\n",
    "W_fused, b_fused = fuse_deconv_bn_1d(\n",
    "    G.d4.deconv.weight,\n",
    "    G.d4.deconv.bias,\n",
    "    G.d4.norm.running_mean,\n",
    "    G.d4.norm.running_var,\n",
    "    G.d4.norm.weight,\n",
    "    G.d4.norm.bias,\n",
    "    eps=G.d4.norm.eps\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Fused Transposed Conv\n",
    "# -------------------------------------------------\n",
    "out_fused_manual = manual_transconv(\n",
    "    x,\n",
    "    W_fused,\n",
    "    b_fused,\n",
    "    s=G.d4.deconv.stride[0],\n",
    "    p=G.d4.deconv.padding[0],\n",
    "    output_padding=G.d4.deconv.output_padding[0]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) ReLU\n",
    "# -------------------------------------------------\n",
    "out_d4_manual = manual_relu(out_fused_manual)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PyTorch reference\n",
    "# -------------------------------------------------\n",
    "with torch.no_grad():\n",
    "    out_deconv_ref = G.d4.deconv(x)\n",
    "    out_bn_ref     = G.d4.norm(out_deconv_ref)\n",
    "    out_d4_ref     = G.d4.act(out_bn_ref)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Verification\n",
    "# -------------------------------------------------\n",
    "print(\"Fused Conv vs (Conv+BN) max abs diff:\",\n",
    "      (out_bn_ref - out_fused_manual).abs().max().item())\n",
    "\n",
    "diff = (out_d4_ref - out_d4_manual).abs()\n",
    "print(\"E1 fused max abs diff:\", diff.max().item())\n",
    "print(\"E1 fused mean abs diff:\", diff.mean().item())\n",
    "print(\"Final RMSE:\", torch.sqrt(torch.mean(diff ** 2)).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
