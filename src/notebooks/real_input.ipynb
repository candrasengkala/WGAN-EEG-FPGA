{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe9f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f9622",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a4caf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BIAS = True\n",
    "DATA_MODE = 5\n",
    "Q_CONFIGS = {\n",
    "    \"Q4.12\": dict(frac_bits=12, int_bits=4, dtype=np.int16),\n",
    "    \"Q10.10\": dict(frac_bits=10, int_bits=10, dtype=np.int32),\n",
    "    \"Q9.14\": dict(frac_bits=14, int_bits=10, dtype=np.int32),\n",
    "}\n",
    "\n",
    "TYPE =  \"Q9.14\" # \"Q4.12\", \"Q10.10\",\"Q9.14\", or \"FLOAT\"\n",
    "\n",
    "TIME_REPEAT = {\n",
    "    \"encoder\":    [256, 128, 64, 32],\n",
    "    \"bottleneck\": [32]*8,\n",
    "    \"decoder\":    [64, 128, 256, 512],\n",
    "    \"out\":        [512]\n",
    "}\n",
    "\n",
    "if TYPE == \"FLOAT\":\n",
    "    MODE = \"FLOAT\"\n",
    "    DTYPE = np.float32\n",
    "else:\n",
    "    MODE = \"FIXED\"\n",
    "    cfg = Q_CONFIGS[TYPE]\n",
    "    FRAC_BITS = cfg[\"frac_bits\"]\n",
    "    INT_BITS  = cfg[\"int_bits\"]\n",
    "    DTYPE     = cfg[\"dtype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e42d97",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003aa1d",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19709e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\data\\eeg_denoise_net\n",
      "EEG shape: (4514, 512)\n",
      "EOG shape: (3400, 512)\n",
      "EMG shape: (5598, 512)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(\"../../data/eeg_denoise_net/\")\n",
    "print(data_path)\n",
    "\n",
    "EEG = np.load(os.path.join(data_path, \"EEG_all_epochs.npy\"))\n",
    "EOG = np.load(os.path.join(data_path, \"EOG_all_epochs.npy\"))\n",
    "EMG = np.load(os.path.join(data_path, \"EMG_all_epochs.npy\"))\n",
    "\n",
    "print(\"EEG shape:\", EEG.shape)\n",
    "print(\"EOG shape:\", EOG.shape)\n",
    "print(\"EMG shape:\", EMG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "798b79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Root Mean Square (RMS) of a 1D signal.\n",
    "    Implements Formula (3).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return np.sqrt(np.mean(x ** 2))\n",
    "\n",
    "def snr_db(clean: np.ndarray, noise: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute SNR in decibels.\n",
    "    Implements Formula (2).\n",
    "    \"\"\"\n",
    "    return 10 * np.log10(rms(clean) / rms(noise))\n",
    "\n",
    "def compute_lambda(clean: np.ndarray, noise: np.ndarray, target_snr_db: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute lambda such that the mixed signal has the desired SNR (in dB).\n",
    "    \"\"\"\n",
    "    return rms(clean) / rms(noise) * 10 ** (-target_snr_db / 10)\n",
    "\n",
    "def mix_signals(clean: np.ndarray, noise: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    Mix clean signal with noise at a target SNR (dB).\n",
    "    \n",
    "    Returns:\n",
    "        mixed_signal\n",
    "        lambda_used\n",
    "    \"\"\"\n",
    "    lam = compute_lambda(clean, noise, target_snr_db)\n",
    "    mixed = clean + lam * noise\n",
    "    return mixed, lam\n",
    "\n",
    "def noisy_eeg_eog(eeg: np.ndarray, eog: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    EEG contaminated by ocular artifacts (EOG).\n",
    "    \"\"\"\n",
    "    return mix_signals(eeg, eog, target_snr_db)\n",
    "\n",
    "def noisy_eeg_emg(eeg: np.ndarray, emg: np.ndarray, target_snr_db: float):\n",
    "    \"\"\"\n",
    "    EEG contaminated by myogenic artifacts (EMG).\n",
    "    \"\"\"\n",
    "    return mix_signals(eeg, emg, target_snr_db)\n",
    "\n",
    "def noisy_eeg_eog_emg(\n",
    "    eeg: np.ndarray,\n",
    "    eog: np.ndarray,\n",
    "    emg: np.ndarray,\n",
    "    target_snr_db: float,\n",
    "    eog_weight: float = 1.0,\n",
    "    emg_weight: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    EEG contaminated by both ocular (EOG) and myogenic (EMG) artifacts.\n",
    "    \n",
    "    eog_weight / emg_weight allow control of relative artifact dominance.\n",
    "    \"\"\"\n",
    "    combined_noise = eog_weight * eog + emg_weight * emg\n",
    "    return mix_signals(eeg, combined_noise, target_snr_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "901e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy_sample(\n",
    "    noisy_signal,\n",
    "    eeg_idx,\n",
    "    eog_idx=None,\n",
    "    emg_idx=None,\n",
    "    snr_db=None,\n",
    "    lambda_used=None\n",
    "):\n",
    "    return {\n",
    "        \"noisy\": noisy_signal,      # np.ndarray (512,)\n",
    "        \"eeg_idx\": eeg_idx,         # int\n",
    "        \"eog_idx\": eog_idx,         # int or None\n",
    "        \"emg_idx\": emg_idx,         # int or None\n",
    "        \"snr_db\": snr_db,           # float\n",
    "        \"lambda\": lambda_used       # float\n",
    "    }\n",
    "\n",
    "def sample_snr_uniform(low, high, rng):\n",
    "    return rng.uniform(low, high)\n",
    "\n",
    "def fixed_snr_list(snrs, rng):\n",
    "    return rng.choice(snrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf0aa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_eeg_eog_paper(\n",
    "    EEG,\n",
    "    EOG,\n",
    "    seed=42,\n",
    "    mode=\"random\"  # \"exhaustive\" | \"random\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    eeg_train_idx = np.arange(3000)\n",
    "    eeg_test_idx  = np.arange(3000, 3400)\n",
    "\n",
    "    snr_grid = np.array([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    if mode == \"exhaustive\":\n",
    "        # ---- training: 10x uniform SNR ----\n",
    "        for _ in range(10):\n",
    "            perm = rng.permutation(eeg_train_idx)\n",
    "            for i in perm:\n",
    "                snr = sample_snr_uniform(-7, 2, rng)\n",
    "                noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "                train_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=i,\n",
    "                        eog_idx=i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # ---- testing: fixed SNR grid ----\n",
    "        for snr in snr_grid:\n",
    "            for i in eeg_test_idx:\n",
    "                noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "                test_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=i,\n",
    "                        eog_idx=i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    elif mode == \"random\":\n",
    "        # ---- training: single pass, random SNR from grid ----\n",
    "        for i in eeg_train_idx:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "            train_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=i,\n",
    "                    eog_idx=i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ---- testing ----\n",
    "        for i in eeg_test_idx:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_eog(EEG[i], EOG[i], snr)\n",
    "\n",
    "            test_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=i,\n",
    "                    eog_idx=i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'exhaustive' or 'random'\")\n",
    "\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def mix_eeg_emg_paper(\n",
    "    EEG,\n",
    "    EMG,\n",
    "    seed=42,\n",
    "    mode=\"random\"  # \"exhaustive\" | \"random\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    eeg_indices = rng.choice(len(EEG), size=len(EMG), replace=True)\n",
    "    emg_indices = np.arange(len(EMG))\n",
    "\n",
    "    pairs = list(zip(eeg_indices, emg_indices))\n",
    "    rng.shuffle(pairs)\n",
    "\n",
    "    train_pairs = pairs[:5000]\n",
    "    test_pairs  = pairs[5000:5598]\n",
    "\n",
    "    snr_grid = np.array([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    if mode == \"exhaustive\":\n",
    "        # ---- training: 10x ----\n",
    "        for _ in range(10):\n",
    "            for eeg_i, emg_i in train_pairs:\n",
    "                snr = sample_snr_uniform(-7, 2, rng)\n",
    "                noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "                train_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=eeg_i,\n",
    "                        emg_idx=emg_i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # ---- testing: fixed grid ----\n",
    "        for snr in snr_grid:\n",
    "            for eeg_i, emg_i in test_pairs:\n",
    "                noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "                test_samples.append(\n",
    "                    make_noisy_sample(\n",
    "                        noisy,\n",
    "                        eeg_idx=eeg_i,\n",
    "                        emg_idx=emg_i,\n",
    "                        snr_db=snr,\n",
    "                        lambda_used=lam\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    elif mode == \"random\":\n",
    "        # ---- training ----\n",
    "        for eeg_i, emg_i in train_pairs:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "            train_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=eeg_i,\n",
    "                    emg_idx=emg_i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ---- testing ----\n",
    "        for eeg_i, emg_i in test_pairs:\n",
    "            snr = rng.choice(snr_grid)\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "            test_samples.append(\n",
    "                make_noisy_sample(\n",
    "                    noisy,\n",
    "                    eeg_idx=eeg_i,\n",
    "                    emg_idx=emg_i,\n",
    "                    snr_db=snr,\n",
    "                    lambda_used=lam\n",
    "                )\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'exhaustive' or 'random'\")\n",
    "\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def mix_custom(\n",
    "    EEG,\n",
    "    EOG=None,\n",
    "    EMG=None,\n",
    "    n_train=10000,\n",
    "    n_test=2000,\n",
    "    snr_range=(-7, 2),\n",
    "    seed=42,\n",
    "    eog_weight=1.0,\n",
    "    emg_weight=1.0\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    def make_one():\n",
    "        eeg_i = rng.integers(len(EEG))\n",
    "        snr = rng.uniform(*snr_range)\n",
    "\n",
    "        eog_i = None\n",
    "        emg_i = None\n",
    "\n",
    "        if EOG is not None and EMG is not None:\n",
    "            eog_i = rng.integers(len(EOG))\n",
    "            emg_i = rng.integers(len(EMG))\n",
    "            noisy, lam = noisy_eeg_eog_emg(\n",
    "                EEG[eeg_i],\n",
    "                EOG[eog_i],\n",
    "                EMG[emg_i],\n",
    "                snr,\n",
    "                eog_weight=eog_weight,\n",
    "                emg_weight=emg_weight\n",
    "            )\n",
    "\n",
    "        elif EOG is not None:\n",
    "            eog_i = rng.integers(len(EOG))\n",
    "            noisy, lam = noisy_eeg_eog(EEG[eeg_i], EOG[eog_i], snr)\n",
    "\n",
    "        elif EMG is not None:\n",
    "            emg_i = rng.integers(len(EMG))\n",
    "            noisy, lam = noisy_eeg_emg(EEG[eeg_i], EMG[emg_i], snr)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"At least one of EOG or EMG must be provided.\")\n",
    "\n",
    "        return make_noisy_sample(\n",
    "            noisy,\n",
    "            eeg_idx=eeg_i,\n",
    "            eog_idx=eog_i,\n",
    "            emg_idx=emg_i,\n",
    "            snr_db=snr,\n",
    "            lambda_used=lam\n",
    "        )\n",
    "\n",
    "    for _ in range(n_train + n_test):\n",
    "        samples.append(make_one())\n",
    "\n",
    "    return samples[:n_train], samples[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a87763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_noisy_sample(sample, EEG):\n",
    "    \"\"\"\n",
    "    Normalize one noisy EEG sample according to EEGdenoiseNet protocol.\n",
    "    \n",
    "    Args:\n",
    "        sample: dict produced by make_noisy_sample\n",
    "        EEG: clean EEG array (for ground truth lookup)\n",
    "    \n",
    "    Returns:\n",
    "        normalized_sample (new dict)\n",
    "    \"\"\"\n",
    "    y = sample[\"noisy\"]\n",
    "    x = EEG[sample[\"eeg_idx\"]]\n",
    "\n",
    "    sigma_y = np.std(y)\n",
    "    if sigma_y == 0:\n",
    "        raise ValueError(\"Standard deviation of noisy signal is zero.\")\n",
    "\n",
    "    normalized_sample = sample.copy()\n",
    "    normalized_sample.update({\n",
    "        \"noisy_norm\": y / sigma_y,     # ŷ\n",
    "        \"clean_norm\": x / sigma_y,     # x̂\n",
    "        \"sigma_y\": sigma_y             # stored for rescaling later\n",
    "    })\n",
    "\n",
    "    return normalized_sample\n",
    "\n",
    "def normalize_dataset(samples, EEG):\n",
    "    \"\"\"\n",
    "    Normalize a list of noisy EEG samples.\n",
    "    \n",
    "    Args:\n",
    "        samples: list of noisy sample dicts\n",
    "        EEG: clean EEG array\n",
    "    \n",
    "    Returns:\n",
    "        list of normalized sample dicts\n",
    "    \"\"\"\n",
    "    return [normalize_noisy_sample(s, EEG) for s in samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231229c4",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "050f8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_MODE == 1: # EEG + EOG Paper\n",
    "    # --- generate noisy datasets (raw, unnormalized) ---\n",
    "    train_samples, test_samples = mix_eeg_eog_paper(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # --- normalize according to EEGdenoiseNet protocol ---\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 2: # EEG + EMG Paper\n",
    "    # --- generate noisy datasets (raw, unnormalized) ---\n",
    "    train_samples, test_samples = mix_eeg_emg_paper(\n",
    "        EEG=EEG,\n",
    "        EMG=EMG,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # --- normalize ---\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 3:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "elif DATA_MODE == 4:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EMG=EMG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n",
    "\n",
    "else:\n",
    "    train_samples, test_samples = mix_custom(\n",
    "        EEG=EEG,\n",
    "        EOG=EOG,\n",
    "        EMG=EMG,\n",
    "        n_train=10000,\n",
    "        n_test=2000,\n",
    "        snr_range=(-7, 2),\n",
    "        seed=42,\n",
    "        eog_weight=1.0,\n",
    "        emg_weight=1.0\n",
    "    )\n",
    "\n",
    "    train_samples_norm = normalize_dataset(train_samples, EEG)\n",
    "    test_samples_norm  = normalize_dataset(test_samples, EEG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec204b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076b939",
   "metadata": {},
   "source": [
    "## Original Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b18f0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=15, s=2, p=7, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'lrelu' or 'relu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DeconvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvTranspose1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=4, s=2, p=1, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'relu' or 'lrelu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.deconv(x)))\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block: (Conv -> BN -> ReLU) x2 + skip\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, k=7, p=3, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n1 = nn.BatchNorm1d(ch)\n",
    "        self.c2 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n2 = nn.BatchNorm1d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.n1(self.c1(x)))\n",
    "        h = self.n2(self.c2(h))\n",
    "        return F.relu(x + h)\n",
    "    \n",
    "class MultiScaleResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale residual block: parallel conv branches (k=3,5,7) then fuse.\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=3, padding=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=5, padding=2, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b7 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=7, padding=3, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.b3(x) + self.b5(x) + self.b7(x)\n",
    "        h = self.fuse(h)\n",
    "        return F.relu(x + h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a278078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Generator (U-Net-ish + Res bottleneck)\n",
    "class GeneratorCNNWGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN U-Net-ish generator for EEG denoising (WGAN).\n",
    "    Input : (B, 1, 512) noisy_norm\n",
    "    Output: (B, 1, 512) clean_norm_hat\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = ConvBlock1D(1, base_ch,       k=16, s=2, p=7, bias=bias, act=\"lrelu\")      # 512 -> 256\n",
    "        self.e2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.e3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.e4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "\n",
    "        # Bottleneck\n",
    "        bn_ch = base_ch * 8\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            ResBlock1D(bn_ch, k=7, p=3, bias=bias) for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        # Decoder (concat doubles channels)\n",
    "        self.d1 = DeconvBlock1D(bn_ch, base_ch*4,   k=4, s=2, p=1, bias=bias, act=\"relu\")     # 32 -> 64\n",
    "        self.d2 = DeconvBlock1D(base_ch*8, base_ch*2, k=4, s=2, p=1,bias=bias, act=\"relu\")   # 64 -> 128\n",
    "        self.d3 = DeconvBlock1D(base_ch*4, base_ch,   k=4, s=2, p=1, bias=bias, act=\"relu\")   # 128 -> 256\n",
    "        self.d4 = DeconvBlock1D(base_ch*2, base_ch//2, k=4, s=2, p=1, bias=bias, act=\"relu\")  # 256 -> 512\n",
    "\n",
    "        # Head (linear output recommended for normalized signals)\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, kernel_size=7, stride=1, padding=3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        # Encoder\n",
    "        s1 = self.e1(y)   # (B, base, 256)\n",
    "        s2 = self.e2(s1)  # (B, 2b, 128)\n",
    "        s3 = self.e3(s2)  # (B, 4b, 64)\n",
    "        s4 = self.e4(s3)  # (B, 8b, 32)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(s4)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        d1 = self.d1(b)                  # (B, 4b, 64)\n",
    "        d1 = torch.cat([d1, s3], dim=1)  # (B, 8b, 64)\n",
    "\n",
    "        d2 = self.d2(d1)                 # (B, 2b, 128)\n",
    "        d2 = torch.cat([d2, s2], dim=1)  # (B, 4b, 128)\n",
    "\n",
    "        d3 = self.d3(d2)                 # (B, b, 256)\n",
    "        d3 = torch.cat([d3, s1], dim=1)  # (B, 2b, 256)\n",
    "\n",
    "        d4 = self.d4(d3)                 # (B, b/2, 512)\n",
    "\n",
    "        return self.out(d4)              # (B, 1, 512)\n",
    "    \n",
    "# Patch Critic (shared by CNN/ResCNN)\n",
    "class CriticPatch1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional PatchGAN critic for WGAN:\n",
    "      D(y, x) -> patch scores\n",
    "    y,x: (B,1,512)\n",
    "    output: (B,1,32)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(2, base_ch, kernel_size=16, stride=2, padding=7, bias=bias)  # 512 -> 256\n",
    "        self.c2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.c3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.c4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "        self.out = nn.Conv1d(base_ch*8, 1, kernel_size=7, stride=1, padding=3, bias=bias)   # 32 -> 32\n",
    "\n",
    "    def forward(self, y, x):\n",
    "        h = torch.cat([y, x], dim=1)  # (B,2,512)\n",
    "        h = F.leaky_relu(self.c1(h), 0.2, inplace=True)\n",
    "        h = self.c2(h)\n",
    "        h = self.c3(h)\n",
    "        h = self.c4(h)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a9853",
   "metadata": {},
   "source": [
    "## Fused Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b381233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedConvBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s, p, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, k, s, p, bias=bias)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class FusedDeconvBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s, p, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, k, s, p, bias=bias)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.deconv(x))\n",
    "\n",
    "class GeneratorCNNWGAN_Fused(nn.Module):\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e1 = FusedConvBlock1D(1, base_ch, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e2 = FusedConvBlock1D(base_ch, base_ch*2, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e3 = FusedConvBlock1D(base_ch*2, base_ch*4, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e4 = FusedConvBlock1D(base_ch*4, base_ch*8, 16, 2, 7, bias, \"lrelu\")\n",
    "\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(base_ch*8, base_ch*8, 7, 1, 3, bias=bias),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(base_ch*8, base_ch*8, 7, 1, 3, bias=bias),\n",
    "            )\n",
    "            for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        self.d1 = FusedDeconvBlock1D(base_ch*8, base_ch*4, 4, 2, 1, bias)\n",
    "        self.d2 = FusedDeconvBlock1D(base_ch*8, base_ch*2, 4, 2, 1, bias)\n",
    "        self.d3 = FusedDeconvBlock1D(base_ch*4, base_ch, 4, 2, 1, bias)\n",
    "        self.d4 = FusedDeconvBlock1D(base_ch*2, base_ch//2, 4, 2, 1, bias)\n",
    "\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, 7, 1, 3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        s1 = self.e1(y)\n",
    "        s2 = self.e2(s1)\n",
    "        s3 = self.e3(s2)\n",
    "        s4 = self.e4(s3)\n",
    "\n",
    "        b = s4\n",
    "        for blk in self.bottleneck:\n",
    "            b = F.relu(b + blk(b))\n",
    "\n",
    "        d1 = torch.cat([self.d1(b), s3], dim=1)\n",
    "        d2 = torch.cat([self.d2(d1), s2], dim=1)\n",
    "        d3 = torch.cat([self.d3(d2), s1], dim=1)\n",
    "        d4 = self.d4(d3)\n",
    "\n",
    "        return self.out(d4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b7e7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(f\"../../test/input_sample_{TYPE}/\")\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "053c768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tensor_mem(tensor, name, path, y_first=True):\n",
    "    \"\"\"\n",
    "    tensor: torch.Tensor, shape [x, y]\n",
    "    writes: name.mem\n",
    "    format: HEX (Q10.10, int32)\n",
    "\n",
    "    order:\n",
    "      y_first=True  → y outer, x inner  (y → x)\n",
    "      y_first=False → x outer, y inner  (x → y)\n",
    "    \"\"\"\n",
    "    assert tensor.ndim == 2, f\"{name} must be 2D\"\n",
    "\n",
    "    # Move to CPU → numpy float\n",
    "    arr_f = tensor.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # Quantize to Q10.10\n",
    "    arr_q = float_to_q(\n",
    "        arr_f,\n",
    "        frac_bits=FRAC_BITS,\n",
    "        int_bits=INT_BITS,\n",
    "        dtype=DTYPE      # np.int32\n",
    "    )\n",
    "\n",
    "    X, Y = arr_q.shape\n",
    "    out_hex_path = os.path.join(path, f\"{name}_hex.mem\")\n",
    "    out_raw_path = os.path.join(path, f\"{name}_raw.mem\")\n",
    "\n",
    "    with open(out_hex_path, \"w\") as f_hex, open(out_raw_path, \"w\") as f_raw:\n",
    "        if y_first:\n",
    "            # y → x\n",
    "            for x in range(X):\n",
    "                for y in range(Y):\n",
    "                    v = int(arr_q[x, y])\n",
    "                    f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "                    f_raw.write(f\"{v}\\n\")\n",
    "        else:\n",
    "            # x → y\n",
    "            for y in range(Y):\n",
    "                for x in range(X):\n",
    "                    v = int(arr_q[x, y])\n",
    "                    f_hex.write(f\"{v & 0xFFFFFFFF:08X}\\n\")\n",
    "                    f_raw.write(f\"{v}\\n\")\n",
    "\n",
    "    order_str = \"y→x\" if y_first else \"x→y\"\n",
    "    print(\n",
    "        f\"Wrote {name}.mem  shape=({X},{Y})  \"\n",
    "        f\"entries={X*Y}  order={order_str}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e768c57",
   "metadata": {},
   "source": [
    "## Model Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfc715ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_bn_1d(\n",
    "    conv_weight,        # (Cout, Cin, K)\n",
    "    conv_bias,          # (Cout,) or None\n",
    "    running_mean,       # (Cout,)\n",
    "    running_var,        # (Cout,)\n",
    "    bn_weight,          # (Cout,) or None (gamma)\n",
    "    bn_bias,            # (Cout,) or None (beta)\n",
    "    eps=1e-5\n",
    "):\n",
    "    Cout = conv_weight.shape[0]\n",
    "\n",
    "    if bn_weight is None:\n",
    "        bn_weight = torch.ones(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "    if bn_bias is None:\n",
    "        bn_bias = torch.zeros(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "    if conv_bias is None:\n",
    "        conv_bias = torch.zeros(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "\n",
    "    denom = torch.sqrt(running_var + eps)          # (Cout,)\n",
    "    scale = bn_weight / denom                      # (Cout,)\n",
    "\n",
    "    # Fuse weight\n",
    "    fused_weight = conv_weight * scale[:, None, None]\n",
    "\n",
    "    # Fuse bias\n",
    "    fused_bias = (conv_bias - running_mean) * scale + bn_bias\n",
    "\n",
    "    return fused_weight, fused_bias\n",
    "\n",
    "def fuse_deconv_bn_1d(\n",
    "    deconv_weight,     # (Cin, Cout, K)\n",
    "    deconv_bias,       # (Cout,) or None\n",
    "    running_mean,      # (Cout,)\n",
    "    running_var,       # (Cout,)\n",
    "    bn_weight,         # (Cout,)\n",
    "    bn_bias,           # (Cout,)\n",
    "    eps\n",
    "):\n",
    "    Cin, Cout, K = deconv_weight.shape\n",
    "\n",
    "    if deconv_bias is None:\n",
    "        deconv_bias = torch.zeros(\n",
    "            Cout,\n",
    "            device=deconv_weight.device,\n",
    "            dtype=deconv_weight.dtype\n",
    "        )\n",
    "\n",
    "    # BN scale\n",
    "    scale = bn_weight / torch.sqrt(running_var + eps)  # (Cout,)\n",
    "\n",
    "    # Fuse weights (scale on Cout dimension)\n",
    "    fused_weight = deconv_weight * scale.view(1, Cout, 1)\n",
    "\n",
    "    # Fuse bias\n",
    "    fused_bias = (deconv_bias - running_mean) * scale + bn_bias\n",
    "\n",
    "    return fused_weight, fused_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d244e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_generator(G):\n",
    "    G_fused = GeneratorCNNWGAN_Fused(bias=True).to(device)\n",
    "    G_fused.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encoder\n",
    "        for i in range(1, 5):\n",
    "            e = getattr(G, f\"e{i}\")\n",
    "            fe = getattr(G_fused, f\"e{i}\")\n",
    "\n",
    "            w, b = fuse_conv_bn_1d(\n",
    "                e.conv.weight, e.conv.bias,\n",
    "                e.norm.running_mean, e.norm.running_var,\n",
    "                e.norm.weight, e.norm.bias\n",
    "            )\n",
    "            fe.conv.weight.copy_(w)\n",
    "            fe.conv.bias.copy_(b)\n",
    "\n",
    "        # Bottleneck\n",
    "        for i, blk in enumerate(G.bottleneck):\n",
    "            fblk = G_fused.bottleneck[i]\n",
    "\n",
    "            for j, (c, n) in enumerate([(blk.c1, blk.n1), (blk.c2, blk.n2)]):\n",
    "                w, b = fuse_conv_bn_1d(\n",
    "                    c.weight, c.bias,\n",
    "                    n.running_mean, n.running_var,\n",
    "                    n.weight, n.bias\n",
    "                )\n",
    "                fblk[j*2].weight.copy_(w)\n",
    "                fblk[j*2].bias.copy_(b)\n",
    "\n",
    "        # Decoder\n",
    "        for i in range(1, 5):\n",
    "            d = getattr(G, f\"d{i}\")\n",
    "            fd = getattr(G_fused, f\"d{i}\")\n",
    "\n",
    "            w, b = fuse_deconv_bn_1d(\n",
    "                d.deconv.weight, d.deconv.bias,\n",
    "                d.norm.running_mean, d.norm.running_var,\n",
    "                d.norm.weight, d.norm.bias,\n",
    "                d.norm.eps\n",
    "            )\n",
    "            fd.deconv.weight.copy_(w)\n",
    "            fd.deconv.bias.copy_(b)\n",
    "\n",
    "        # Output\n",
    "        G_fused.out.weight.copy_(G.out.weight)\n",
    "        G_fused.out.bias.copy_(G.out.bias)\n",
    "\n",
    "    return G_fused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e8ff5",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7e580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d5_b\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(f\"../models/main3_d{DATA_MODE}_{\"b\" if BIAS else \"nb\"}/\")\n",
    "print(data_path)\n",
    "\n",
    "pattern = re.compile(r\"^cnn_([DG])_\\d{8}_\\d{6}\\.pth$\")\n",
    "\n",
    "cnn_G_path = None\n",
    "cnn_D_path = None\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "    m = pattern.match(f)\n",
    "    if m:\n",
    "        full = os.path.join(data_path, f)\n",
    "        if m.group(1) == \"G\":\n",
    "            cnn_G_path = full\n",
    "        else:\n",
    "            cnn_D_path = full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8a1ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorCNNWGAN(\n",
      "  (e1): ConvBlock1D(\n",
      "    (conv): Conv1d(1, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d1): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d2): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d3): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(128, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d4): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(64, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "CriticPatch1D(\n",
      "  (c1): Conv1d(2, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "  (c2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(256, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_23348\\1880236742.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_23348\\1880236742.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "G = GeneratorCNNWGAN(bias=BIAS).to(device)\n",
    "D = CriticPatch1D(bias=BIAS).to(device)\n",
    "\n",
    "G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
    "D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n",
    "\n",
    "print(G.eval())\n",
    "print(D.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfb437e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_fused = fuse_generator(G)\n",
    "\n",
    "# fused_G_path = os.path.join(\n",
    "#     data_path,\n",
    "#     \"fused_\" + os.path.basename(cnn_G_path)\n",
    "# )\n",
    "\n",
    "# torch.save(G_fused.state_dict(), fused_G_path)\n",
    "# print(\"Saved:\", fused_G_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff044a",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e704d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_q(x, frac_bits, int_bits, dtype):\n",
    "    scale = 1 << frac_bits\n",
    "    total_bits = int_bits + frac_bits\n",
    "    min_val = -(1 << (total_bits - 1))\n",
    "    max_val = (1 << (total_bits - 1)) - 1\n",
    "\n",
    "    xq = np.round(x * scale)\n",
    "    xq = np.clip(xq, min_val, max_val)\n",
    "    return xq.astype(dtype)\n",
    "\n",
    "def q_to_float(x, frac_bits):\n",
    "    return x.astype(np.float32) / (1 << frac_bits)\n",
    "\n",
    "def q_to_hex(arr):\n",
    "    assert isinstance(arr, np.ndarray), \"Input must be a numpy array\"\n",
    "\n",
    "    vec_hex = np.vectorize(lambda v: f\"{int(v) & 0xFFFFFFFF:08X}\\n\")\n",
    "    return vec_hex(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959e2dd",
   "metadata": {},
   "source": [
    "# Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787f7f5",
   "metadata": {},
   "source": [
    "## Initial Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d29f1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1234, 420, 67, 69, 3100, 3051, 3075, 42, 21, 20]\n"
     ]
    }
   ],
   "source": [
    "seed_arr_ori = [1234, 420, 67, 69, 13523100, 13223051, 13223075, 42, 21, 20]\n",
    "seed_arr = [x % len(train_samples_norm) for x in seed_arr_ori]\n",
    "print(seed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b15d858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy\n",
      "eeg_idx\n",
      "eog_idx\n",
      "emg_idx\n",
      "snr_db\n",
      "lambda\n",
      "noisy_norm\n",
      "clean_norm\n",
      "sigma_y\n"
     ]
    }
   ],
   "source": [
    "for x in train_samples_norm[1234].keys():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "285c16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "\n",
    "for seed in seed_arr_ori:\n",
    "    seeded_data = {}\n",
    "\n",
    "    mod_seed = seed % len(train_samples_norm)\n",
    "    seeded_data[\"raw_seed\"] = seed\n",
    "    seeded_data[\"mod_seed\"] = mod_seed\n",
    "\n",
    "    inp = train_samples_norm[mod_seed][\"noisy_norm\"]\n",
    "    \n",
    "    if isinstance(inp, np.ndarray):\n",
    "        inp = torch.from_numpy(inp)\n",
    "    inp = inp.float().to(next(G.parameters()).device)\n",
    "    inp = inp.unsqueeze(0)\n",
    "    inp = inp.unsqueeze(0)\n",
    "\n",
    "    seeded_data[\"input\"] = inp\n",
    "\n",
    "    raw_data.append(seeded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "accb642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(raw_data[0][\"input\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bea1ca",
   "metadata": {},
   "source": [
    "## Input Through Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce5d423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input in raw_data:\n",
    "    G.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input[\"e1\"] = G.e1(input[\"input\"])\n",
    "        input[\"e2\"] = G.e2(input[\"e1\"])\n",
    "        input[\"e3\"] = G.e3(input[\"e2\"])\n",
    "        input[\"e4\"] = G.e4(input[\"e3\"])\n",
    "\n",
    "        input[\"b0\"] = G.bottleneck[0](input[\"e4\"])\n",
    "        input[\"b1\"] = G.bottleneck[1](input[\"b0\"])\n",
    "        input[\"b2\"] = G.bottleneck[2](input[\"b1\"])\n",
    "        input[\"b3\"] = G.bottleneck[3](input[\"b2\"])\n",
    "\n",
    "        input[\"d1\"] = G.d1(input[\"b3\"])\n",
    "        d2_input = torch.cat([input[\"d1\"], input[\"e3\"]], dim=1)\n",
    "        input[\"d2_in\"] = d2_input\n",
    "        input[\"d2_out\"] = G.d2(d2_input)\n",
    "        d3_input = torch.cat([input[\"d2_out\"], input[\"e2\"]], dim=1)\n",
    "        input[\"d3_in\"] = d3_input\n",
    "        input[\"d3_out\"] = G.d3(d3_input)\n",
    "        d4_input = torch.cat([input[\"d3_out\"], input[\"e1\"]], dim=1)\n",
    "        input[\"d4_in\"] = d4_input\n",
    "        input[\"d4_out\"] = G.d4(d4_input)\n",
    "\n",
    "        input[\"out\"] = G.out(input[\"d4_out\"])\n",
    "\n",
    "for sample in raw_data:\n",
    "    G_fused.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample[\"e1_fused\"] = G_fused.e1(sample[\"input\"])\n",
    "        sample[\"e2_fused\"] = G_fused.e2(sample[\"e1_fused\"])\n",
    "        sample[\"e3_fused\"] = G_fused.e3(sample[\"e2_fused\"])\n",
    "        sample[\"e4_fused\"] = G_fused.e4(sample[\"e3_fused\"])\n",
    "\n",
    "        sample[\"b0_fused\"] = G_fused.bottleneck[0](sample[\"e4_fused\"])\n",
    "        sample[\"b1_fused\"] = G_fused.bottleneck[1](sample[\"b0_fused\"])\n",
    "        sample[\"b2_fused\"] = G_fused.bottleneck[2](sample[\"b1_fused\"])\n",
    "        sample[\"b3_fused\"] = G_fused.bottleneck[3](sample[\"b2_fused\"])\n",
    "\n",
    "        sample[\"d1_fused\"] = G_fused.d1(sample[\"b3_fused\"])\n",
    "        d2_input_fused = torch.cat([sample[\"d1_fused\"], sample[\"e3_fused\"]],dim=1)\n",
    "        sample[\"d2_in_fused\"] = d2_input_fused\n",
    "        sample[\"d2_out_fused\"] = G_fused.d2(d2_input_fused)\n",
    "        d3_input_fused = torch.cat([sample[\"d2_out_fused\"], sample[\"e2_fused\"]],dim=1)\n",
    "        sample[\"d3_in_fused\"] = d3_input_fused\n",
    "        sample[\"d3_out_fused\"] = G_fused.d3(d3_input_fused)\n",
    "        d4_input_fused = torch.cat([sample[\"d3_out_fused\"], sample[\"e1_fused\"]],dim=1)\n",
    "        sample[\"d4_in_fused\"] = d4_input_fused\n",
    "        sample[\"d4_out_fused\"] = G_fused.d4(d4_input_fused)\n",
    "\n",
    "        sample[\"out_fused\"] = G_fused.out(sample[\"d4_out_fused\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4762f525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input          : (512,)\n",
      "e1             : (32, 256)\n",
      "e2             : (64, 128)\n",
      "e3             : (128, 64)\n",
      "e4             : (256, 32)\n",
      "b0             : (256, 32)\n",
      "b1             : (256, 32)\n",
      "b2             : (256, 32)\n",
      "b3             : (256, 32)\n",
      "d1             : (128, 64)\n",
      "d2_in          : (256, 64)\n",
      "d2_out         : (64, 128)\n",
      "d3_in          : (128, 128)\n",
      "d3_out         : (32, 256)\n",
      "d4_in          : (64, 256)\n",
      "d4_out         : (16, 512)\n",
      "out            : (512,)\n",
      "e1_fused       : (32, 256)\n",
      "e2_fused       : (64, 128)\n",
      "e3_fused       : (128, 64)\n",
      "e4_fused       : (256, 32)\n",
      "b0_fused       : (256, 32)\n",
      "b1_fused       : (256, 32)\n",
      "b2_fused       : (256, 32)\n",
      "b3_fused       : (256, 32)\n",
      "d1_fused       : (128, 64)\n",
      "d2_in_fused    : (256, 64)\n",
      "d2_out_fused   : (64, 128)\n",
      "d3_in_fused    : (128, 128)\n",
      "d3_out_fused   : (32, 256)\n",
      "d4_in_fused    : (64, 256)\n",
      "d4_out_fused   : (16, 512)\n",
      "out_fused      : (512,)\n"
     ]
    }
   ],
   "source": [
    "# for i, sample in enumerate(raw_data):\n",
    "#     print(f\"\\n=== Sample {i} ===\")\n",
    "#     for k, v in sample.items():\n",
    "#         if torch.is_tensor(v):\n",
    "#             print(f\"{k:10s}: {tuple(v.shape)}\")\n",
    "#     break\n",
    "\n",
    "for sample in raw_data:\n",
    "    for k, v in sample.items():\n",
    "        if torch.is_tensor(v) and v.dim() > 0 and v.shape[0] == 1:\n",
    "            sample[k] = v.squeeze(0)\n",
    "\n",
    "sample = raw_data[0]\n",
    "for k, v in sample.items():\n",
    "    if torch.is_tensor(v):\n",
    "        print(f\"{k:15s}: {tuple(v.shape)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0cf41",
   "metadata": {},
   "source": [
    "# Quantize and Hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 0 (_q shapes) ===\n",
      "input_q        : (512,)\n",
      "e1_q           : (32, 256)\n",
      "e2_q           : (64, 128)\n",
      "e3_q           : (128, 64)\n",
      "e4_q           : (256, 32)\n",
      "b0_q           : (256, 32)\n",
      "b1_q           : (256, 32)\n",
      "b2_q           : (256, 32)\n",
      "b3_q           : (256, 32)\n",
      "d1_q           : (128, 64)\n",
      "d2_in_q        : (256, 64)\n",
      "d2_out_q       : (64, 128)\n",
      "d3_in_q        : (128, 128)\n",
      "d3_out_q       : (32, 256)\n",
      "d4_in_q        : (64, 256)\n",
      "d4_out_q       : (16, 512)\n",
      "out_q          : (512,)\n",
      "e1_fused_q     : (32, 256)\n",
      "e2_fused_q     : (64, 128)\n",
      "e3_fused_q     : (128, 64)\n",
      "e4_fused_q     : (256, 32)\n",
      "b0_fused_q     : (256, 32)\n",
      "b1_fused_q     : (256, 32)\n",
      "b2_fused_q     : (256, 32)\n",
      "b3_fused_q     : (256, 32)\n",
      "d1_fused_q     : (128, 64)\n",
      "d2_in_fused_q  : (256, 64)\n",
      "d2_out_fused_q : (64, 128)\n",
      "d3_in_fused_q  : (128, 128)\n",
      "d3_out_fused_q : (32, 256)\n",
      "d4_in_fused_q  : (64, 256)\n",
      "d4_out_fused_q : (16, 512)\n",
      "out_fused_q    : (512,)\n",
      "input_hex      : (512,)\n",
      "e1_hex         : (32, 256)\n",
      "e2_hex         : (64, 128)\n",
      "e3_hex         : (128, 64)\n",
      "e4_hex         : (256, 32)\n",
      "b0_hex         : (256, 32)\n",
      "b1_hex         : (256, 32)\n",
      "b2_hex         : (256, 32)\n",
      "b3_hex         : (256, 32)\n",
      "d1_hex         : (128, 64)\n",
      "d2_in_hex      : (256, 64)\n",
      "d2_out_hex     : (64, 128)\n",
      "d3_in_hex      : (128, 128)\n",
      "d3_out_hex     : (32, 256)\n",
      "d4_in_hex      : (64, 256)\n",
      "d4_out_hex     : (16, 512)\n",
      "out_hex        : (512,)\n",
      "e1_fused_hex   : (32, 256)\n",
      "e2_fused_hex   : (64, 128)\n",
      "e3_fused_hex   : (128, 64)\n",
      "e4_fused_hex   : (256, 32)\n",
      "b0_fused_hex   : (256, 32)\n",
      "b1_fused_hex   : (256, 32)\n",
      "b2_fused_hex   : (256, 32)\n",
      "b3_fused_hex   : (256, 32)\n",
      "d1_fused_hex   : (128, 64)\n",
      "d2_in_fused_hex: (256, 64)\n",
      "d2_out_fused_hex: (64, 128)\n",
      "d3_in_fused_hex: (128, 128)\n",
      "d3_out_fused_hex: (32, 256)\n",
      "d4_in_fused_hex: (64, 256)\n",
      "d4_out_fused_hex: (16, 512)\n",
      "out_fused_hex  : (512,)\n"
     ]
    }
   ],
   "source": [
    "for sample in raw_data:\n",
    "    tensor_keys = [\n",
    "        k for k, v in sample.items()\n",
    "        if torch.is_tensor(v)\n",
    "    ]\n",
    "\n",
    "    for k in tensor_keys:\n",
    "        v = sample[k]\n",
    "\n",
    "        v_f = v.detach().cpu().numpy().astype(np.float32)\n",
    "        q = float_to_q(\n",
    "            v_f,\n",
    "            frac_bits=FRAC_BITS,\n",
    "            int_bits=INT_BITS,\n",
    "            dtype=DTYPE\n",
    "        )\n",
    "\n",
    "        sample[f\"{k}_q\"] = q\n",
    "        sample[f\"{k}_hex\"] = q_to_hex(q)\n",
    "\n",
    "# for i, sample in enumerate(raw_data):\n",
    "#     print(f\"\\n=== Sample {i} (_q shapes) ===\")\n",
    "#     for k, v in sample.items():\n",
    "#         if isinstance(v, np.ndarray):\n",
    "#             print(f\"{k:15s}: {v.shape}\")\n",
    "#     break   # remove if you want all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80178c4f",
   "metadata": {},
   "source": [
    "# Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data_path = os.path.abspath(f\"../../test/io_sample/\")\n",
    "os.makedirs(group_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
