{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566e83bb",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "466b6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f995e8f",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7f29c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=15, s=2, p=7, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'lrelu' or 'relu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DeconvBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    ConvTranspose1d -> BatchNorm1d -> Activation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=4, s=2, p=1, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=bias)\n",
    "        self.norm = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'relu' or 'lrelu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.deconv(x)))\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block: (Conv -> BN -> ReLU) x2 + skip\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, k=7, p=3, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n1 = nn.BatchNorm1d(ch)\n",
    "        self.c2 = nn.Conv1d(ch, ch, kernel_size=k, stride=1, padding=p, bias=bias)\n",
    "        self.n2 = nn.BatchNorm1d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.n1(self.c1(x)))\n",
    "        h = self.n2(self.c2(h))\n",
    "        return F.relu(x + h)\n",
    "    \n",
    "class MultiScaleResBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale residual block: parallel conv branches (k=3,5,7) then fuse.\n",
    "    Keeps same channel count and length.\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=3, padding=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=5, padding=2, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.b7 = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=7, padding=3, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.b3(x) + self.b5(x) + self.b7(x)\n",
    "        h = self.fuse(h)\n",
    "        return F.relu(x + h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "56b22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Generator (U-Net-ish + Res bottleneck)\n",
    "class GeneratorCNNWGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN U-Net-ish generator for EEG denoising (WGAN).\n",
    "    Input : (B, 1, 512) noisy_norm\n",
    "    Output: (B, 1, 512) clean_norm_hat\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = ConvBlock1D(1, base_ch,       k=16, s=2, p=7, bias=bias, act=\"lrelu\")      # 512 -> 256\n",
    "        self.e2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.e3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.e4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "\n",
    "        # Bottleneck\n",
    "        bn_ch = base_ch * 8\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            ResBlock1D(bn_ch, k=7, p=3, bias=bias) for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        # Decoder (concat doubles channels)\n",
    "        self.d1 = DeconvBlock1D(bn_ch, base_ch*4,   k=4, s=2, p=1, bias=bias, act=\"relu\")     # 32 -> 64\n",
    "        self.d2 = DeconvBlock1D(base_ch*8, base_ch*2, k=4, s=2, p=1,bias=bias, act=\"relu\")   # 64 -> 128\n",
    "        self.d3 = DeconvBlock1D(base_ch*4, base_ch,   k=4, s=2, p=1, bias=bias, act=\"relu\")   # 128 -> 256\n",
    "        self.d4 = DeconvBlock1D(base_ch*2, base_ch//2, k=4, s=2, p=1, bias=bias, act=\"relu\")  # 256 -> 512\n",
    "\n",
    "        # Head (linear output recommended for normalized signals)\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, kernel_size=7, stride=1, padding=3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        # Encoder\n",
    "        s1 = self.e1(y)   # (B, base, 256)\n",
    "        s2 = self.e2(s1)  # (B, 2b, 128)\n",
    "        s3 = self.e3(s2)  # (B, 4b, 64)\n",
    "        s4 = self.e4(s3)  # (B, 8b, 32)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(s4)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        d1 = self.d1(b)                  # (B, 4b, 64)\n",
    "        d1 = torch.cat([d1, s3], dim=1)  # (B, 8b, 64)\n",
    "\n",
    "        d2 = self.d2(d1)                 # (B, 2b, 128)\n",
    "        d2 = torch.cat([d2, s2], dim=1)  # (B, 4b, 128)\n",
    "\n",
    "        d3 = self.d3(d2)                 # (B, b, 256)\n",
    "        d3 = torch.cat([d3, s1], dim=1)  # (B, 2b, 256)\n",
    "\n",
    "        d4 = self.d4(d3)                 # (B, b/2, 512)\n",
    "\n",
    "        return self.out(d4)              # (B, 1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0ef71ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Critic (shared by CNN/ResCNN)\n",
    "class CriticPatch1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional PatchGAN critic for WGAN:\n",
    "      D(y, x) -> patch scores\n",
    "    y,x: (B,1,512)\n",
    "    output: (B,1,32)\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ch=32, bias=True):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(2, base_ch, kernel_size=16, stride=2, padding=7, bias=bias)  # 512 -> 256\n",
    "        self.c2 = ConvBlock1D(base_ch, base_ch*2, k=16, s=2, p=7, bias=bias, act=\"lrelu\")    # 256 -> 128\n",
    "        self.c3 = ConvBlock1D(base_ch*2, base_ch*4, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 128 -> 64\n",
    "        self.c4 = ConvBlock1D(base_ch*4, base_ch*8, k=16, s=2, p=7, bias=bias, act=\"lrelu\")  # 64 -> 32\n",
    "        self.out = nn.Conv1d(base_ch*8, 1, kernel_size=7, stride=1, padding=3, bias=bias)   # 32 -> 32\n",
    "\n",
    "    def forward(self, y, x):\n",
    "        h = torch.cat([y, x], dim=1)  # (B,2,512)\n",
    "        h = F.leaky_relu(self.c1(h), 0.2, inplace=True)\n",
    "        h = self.c2(h)\n",
    "        h = self.c3(h)\n",
    "        h = self.c4(h)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ea6ed",
   "metadata": {},
   "source": [
    "# Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "45b10b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS = True\n",
    "DATA_MODE = 1 # up to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3b2bbd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\n",
      "G: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\\cnn_G_20260113_074150.pth\n",
      "D: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\\cnn_D_20260113_074150.pth\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.abspath(f\"../models/main3_d{DATA_MODE}_{\"b\" if BIAS else \"nb\"}/\")\n",
    "print(data_path)\n",
    "\n",
    "pattern = re.compile(r\"^cnn_([DG])_\\d{8}_\\d{6}\\.pth$\")\n",
    "\n",
    "cnn_G_path = None\n",
    "cnn_D_path = None\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "    m = pattern.match(f)\n",
    "    if m:\n",
    "        full = os.path.join(data_path, f)\n",
    "        if m.group(1) == \"G\":\n",
    "            cnn_G_path = full\n",
    "        else:\n",
    "            cnn_D_path = full\n",
    "\n",
    "print(\"G:\", cnn_G_path)\n",
    "print(\"D:\", cnn_D_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2e795bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorCNNWGAN(\n",
      "  (e1): ConvBlock1D(\n",
      "    (conv): Conv1d(1, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (e4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock1D(\n",
      "      (c1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (c2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (n2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (d1): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d2): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(256, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d3): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(128, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (d4): DeconvBlock1D(\n",
      "    (deconv): ConvTranspose1d(64, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "    (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(16, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "CriticPatch1D(\n",
      "  (c1): Conv1d(2, 32, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "  (c2): ConvBlock1D(\n",
      "    (conv): Conv1d(32, 64, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c3): ConvBlock1D(\n",
      "    (conv): Conv1d(64, 128, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (c4): ConvBlock1D(\n",
      "    (conv): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
      "    (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (out): Conv1d(256, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_19204\\700924479.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_19204\\700924479.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = GeneratorCNNWGAN(bias=BIAS).to(device)\n",
    "D = CriticPatch1D(bias=BIAS).to(device)\n",
    "\n",
    "G.load_state_dict(torch.load(cnn_G_path, map_location=device))\n",
    "D.load_state_dict(torch.load(cnn_D_path, map_location=device))\n",
    "\n",
    "print(G.eval())\n",
    "print(D.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a97fd7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> GeneratorCNNWGAN\n",
      "e1 -> ConvBlock1D\n",
      "e1.conv -> Conv1d\n",
      "e1.norm -> BatchNorm1d\n",
      "e1.act -> LeakyReLU\n",
      "e2 -> ConvBlock1D\n",
      "e2.conv -> Conv1d\n",
      "e2.norm -> BatchNorm1d\n",
      "e2.act -> LeakyReLU\n",
      "e3 -> ConvBlock1D\n",
      "e3.conv -> Conv1d\n",
      "e3.norm -> BatchNorm1d\n",
      "e3.act -> LeakyReLU\n",
      "e4 -> ConvBlock1D\n",
      "e4.conv -> Conv1d\n",
      "e4.norm -> BatchNorm1d\n",
      "e4.act -> LeakyReLU\n",
      "bottleneck -> Sequential\n",
      "bottleneck.0 -> ResBlock1D\n",
      "bottleneck.0.c1 -> Conv1d\n",
      "bottleneck.0.n1 -> BatchNorm1d\n",
      "bottleneck.0.c2 -> Conv1d\n",
      "bottleneck.0.n2 -> BatchNorm1d\n",
      "bottleneck.1 -> ResBlock1D\n",
      "bottleneck.1.c1 -> Conv1d\n",
      "bottleneck.1.n1 -> BatchNorm1d\n",
      "bottleneck.1.c2 -> Conv1d\n",
      "bottleneck.1.n2 -> BatchNorm1d\n",
      "bottleneck.2 -> ResBlock1D\n",
      "bottleneck.2.c1 -> Conv1d\n",
      "bottleneck.2.n1 -> BatchNorm1d\n",
      "bottleneck.2.c2 -> Conv1d\n",
      "bottleneck.2.n2 -> BatchNorm1d\n",
      "bottleneck.3 -> ResBlock1D\n",
      "bottleneck.3.c1 -> Conv1d\n",
      "bottleneck.3.n1 -> BatchNorm1d\n",
      "bottleneck.3.c2 -> Conv1d\n",
      "bottleneck.3.n2 -> BatchNorm1d\n",
      "d1 -> DeconvBlock1D\n",
      "d1.deconv -> ConvTranspose1d\n",
      "d1.norm -> BatchNorm1d\n",
      "d1.act -> ReLU\n",
      "d2 -> DeconvBlock1D\n",
      "d2.deconv -> ConvTranspose1d\n",
      "d2.norm -> BatchNorm1d\n",
      "d2.act -> ReLU\n",
      "d3 -> DeconvBlock1D\n",
      "d3.deconv -> ConvTranspose1d\n",
      "d3.norm -> BatchNorm1d\n",
      "d3.act -> ReLU\n",
      "d4 -> DeconvBlock1D\n",
      "d4.deconv -> ConvTranspose1d\n",
      "d4.norm -> BatchNorm1d\n",
      "d4.act -> ReLU\n",
      "out -> Conv1d\n",
      "\n",
      "================================================================================\n",
      "\n",
      " -> CriticPatch1D\n",
      "c1 -> Conv1d\n",
      "c2 -> ConvBlock1D\n",
      "c2.conv -> Conv1d\n",
      "c2.norm -> BatchNorm1d\n",
      "c2.act -> LeakyReLU\n",
      "c3 -> ConvBlock1D\n",
      "c3.conv -> Conv1d\n",
      "c3.norm -> BatchNorm1d\n",
      "c3.act -> LeakyReLU\n",
      "c4 -> ConvBlock1D\n",
      "c4.conv -> Conv1d\n",
      "c4.norm -> BatchNorm1d\n",
      "c4.act -> LeakyReLU\n",
      "out -> Conv1d\n"
     ]
    }
   ],
   "source": [
    "for name, module in G.named_modules():\n",
    "    print(name, \"->\", module.__class__.__name__)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, module in D.named_modules():\n",
    "    print(name, \"->\", module.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4663f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1.conv.weight torch.Size([32, 1, 16]) True\n",
      "e1.conv.bias torch.Size([32]) True\n",
      "e1.norm.weight torch.Size([32]) True\n",
      "e1.norm.bias torch.Size([32]) True\n",
      "e2.conv.weight torch.Size([64, 32, 16]) True\n",
      "e2.conv.bias torch.Size([64]) True\n",
      "e2.norm.weight torch.Size([64]) True\n",
      "e2.norm.bias torch.Size([64]) True\n",
      "e3.conv.weight torch.Size([128, 64, 16]) True\n",
      "e3.conv.bias torch.Size([128]) True\n",
      "e3.norm.weight torch.Size([128]) True\n",
      "e3.norm.bias torch.Size([128]) True\n",
      "e4.conv.weight torch.Size([256, 128, 16]) True\n",
      "e4.conv.bias torch.Size([256]) True\n",
      "e4.norm.weight torch.Size([256]) True\n",
      "e4.norm.bias torch.Size([256]) True\n",
      "bottleneck.0.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.0.c1.bias torch.Size([256]) True\n",
      "bottleneck.0.n1.weight torch.Size([256]) True\n",
      "bottleneck.0.n1.bias torch.Size([256]) True\n",
      "bottleneck.0.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.0.c2.bias torch.Size([256]) True\n",
      "bottleneck.0.n2.weight torch.Size([256]) True\n",
      "bottleneck.0.n2.bias torch.Size([256]) True\n",
      "bottleneck.1.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.1.c1.bias torch.Size([256]) True\n",
      "bottleneck.1.n1.weight torch.Size([256]) True\n",
      "bottleneck.1.n1.bias torch.Size([256]) True\n",
      "bottleneck.1.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.1.c2.bias torch.Size([256]) True\n",
      "bottleneck.1.n2.weight torch.Size([256]) True\n",
      "bottleneck.1.n2.bias torch.Size([256]) True\n",
      "bottleneck.2.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.2.c1.bias torch.Size([256]) True\n",
      "bottleneck.2.n1.weight torch.Size([256]) True\n",
      "bottleneck.2.n1.bias torch.Size([256]) True\n",
      "bottleneck.2.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.2.c2.bias torch.Size([256]) True\n",
      "bottleneck.2.n2.weight torch.Size([256]) True\n",
      "bottleneck.2.n2.bias torch.Size([256]) True\n",
      "bottleneck.3.c1.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.3.c1.bias torch.Size([256]) True\n",
      "bottleneck.3.n1.weight torch.Size([256]) True\n",
      "bottleneck.3.n1.bias torch.Size([256]) True\n",
      "bottleneck.3.c2.weight torch.Size([256, 256, 7]) True\n",
      "bottleneck.3.c2.bias torch.Size([256]) True\n",
      "bottleneck.3.n2.weight torch.Size([256]) True\n",
      "bottleneck.3.n2.bias torch.Size([256]) True\n",
      "d1.deconv.weight torch.Size([256, 128, 4]) True\n",
      "d1.deconv.bias torch.Size([128]) True\n",
      "d1.norm.weight torch.Size([128]) True\n",
      "d1.norm.bias torch.Size([128]) True\n",
      "d2.deconv.weight torch.Size([256, 64, 4]) True\n",
      "d2.deconv.bias torch.Size([64]) True\n",
      "d2.norm.weight torch.Size([64]) True\n",
      "d2.norm.bias torch.Size([64]) True\n",
      "d3.deconv.weight torch.Size([128, 32, 4]) True\n",
      "d3.deconv.bias torch.Size([32]) True\n",
      "d3.norm.weight torch.Size([32]) True\n",
      "d3.norm.bias torch.Size([32]) True\n",
      "d4.deconv.weight torch.Size([64, 16, 4]) True\n",
      "d4.deconv.bias torch.Size([16]) True\n",
      "d4.norm.weight torch.Size([16]) True\n",
      "d4.norm.bias torch.Size([16]) True\n",
      "out.weight torch.Size([1, 16, 7]) True\n",
      "out.bias torch.Size([1]) True\n",
      "\n",
      "================================================================================\n",
      "\n",
      "c1.weight torch.Size([32, 2, 16]) True\n",
      "c1.bias torch.Size([32]) True\n",
      "c2.conv.weight torch.Size([64, 32, 16]) True\n",
      "c2.conv.bias torch.Size([64]) True\n",
      "c2.norm.weight torch.Size([64]) True\n",
      "c2.norm.bias torch.Size([64]) True\n",
      "c3.conv.weight torch.Size([128, 64, 16]) True\n",
      "c3.conv.bias torch.Size([128]) True\n",
      "c3.norm.weight torch.Size([128]) True\n",
      "c3.norm.bias torch.Size([128]) True\n",
      "c4.conv.weight torch.Size([256, 128, 16]) True\n",
      "c4.conv.bias torch.Size([256]) True\n",
      "c4.norm.weight torch.Size([256]) True\n",
      "c4.norm.bias torch.Size([256]) True\n",
      "out.weight torch.Size([1, 256, 7]) True\n",
      "out.bias torch.Size([1]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in G.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, param in D.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "921e8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1.norm.running_mean torch.Size([32])\n",
      "e1.norm.running_var torch.Size([32])\n",
      "e1.norm.num_batches_tracked torch.Size([])\n",
      "e2.norm.running_mean torch.Size([64])\n",
      "e2.norm.running_var torch.Size([64])\n",
      "e2.norm.num_batches_tracked torch.Size([])\n",
      "e3.norm.running_mean torch.Size([128])\n",
      "e3.norm.running_var torch.Size([128])\n",
      "e3.norm.num_batches_tracked torch.Size([])\n",
      "e4.norm.running_mean torch.Size([256])\n",
      "e4.norm.running_var torch.Size([256])\n",
      "e4.norm.num_batches_tracked torch.Size([])\n",
      "bottleneck.0.n1.running_mean torch.Size([256])\n",
      "bottleneck.0.n1.running_var torch.Size([256])\n",
      "bottleneck.0.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.0.n2.running_mean torch.Size([256])\n",
      "bottleneck.0.n2.running_var torch.Size([256])\n",
      "bottleneck.0.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.1.n1.running_mean torch.Size([256])\n",
      "bottleneck.1.n1.running_var torch.Size([256])\n",
      "bottleneck.1.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.1.n2.running_mean torch.Size([256])\n",
      "bottleneck.1.n2.running_var torch.Size([256])\n",
      "bottleneck.1.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.2.n1.running_mean torch.Size([256])\n",
      "bottleneck.2.n1.running_var torch.Size([256])\n",
      "bottleneck.2.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.2.n2.running_mean torch.Size([256])\n",
      "bottleneck.2.n2.running_var torch.Size([256])\n",
      "bottleneck.2.n2.num_batches_tracked torch.Size([])\n",
      "bottleneck.3.n1.running_mean torch.Size([256])\n",
      "bottleneck.3.n1.running_var torch.Size([256])\n",
      "bottleneck.3.n1.num_batches_tracked torch.Size([])\n",
      "bottleneck.3.n2.running_mean torch.Size([256])\n",
      "bottleneck.3.n2.running_var torch.Size([256])\n",
      "bottleneck.3.n2.num_batches_tracked torch.Size([])\n",
      "d1.norm.running_mean torch.Size([128])\n",
      "d1.norm.running_var torch.Size([128])\n",
      "d1.norm.num_batches_tracked torch.Size([])\n",
      "d2.norm.running_mean torch.Size([64])\n",
      "d2.norm.running_var torch.Size([64])\n",
      "d2.norm.num_batches_tracked torch.Size([])\n",
      "d3.norm.running_mean torch.Size([32])\n",
      "d3.norm.running_var torch.Size([32])\n",
      "d3.norm.num_batches_tracked torch.Size([])\n",
      "d4.norm.running_mean torch.Size([16])\n",
      "d4.norm.running_var torch.Size([16])\n",
      "d4.norm.num_batches_tracked torch.Size([])\n",
      "\n",
      "================================================================================\n",
      "\n",
      "c2.norm.running_mean torch.Size([64])\n",
      "c2.norm.running_var torch.Size([64])\n",
      "c2.norm.num_batches_tracked torch.Size([])\n",
      "c3.norm.running_mean torch.Size([128])\n",
      "c3.norm.running_var torch.Size([128])\n",
      "c3.norm.num_batches_tracked torch.Size([])\n",
      "c4.norm.running_mean torch.Size([256])\n",
      "c4.norm.running_var torch.Size([256])\n",
      "c4.norm.num_batches_tracked torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for name, buf in G.named_buffers():\n",
    "    print(name, buf.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 +\"\\n\")\n",
    "\n",
    "for name, buf in D.named_buffers():\n",
    "    print(name, buf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2b761e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BN layer: e1.norm\n",
      " running_mean: torch.Size([32])\n",
      " running_var : torch.Size([32])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e2.norm\n",
      " running_mean: torch.Size([64])\n",
      " running_var : torch.Size([64])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e3.norm\n",
      " running_mean: torch.Size([128])\n",
      " running_var : torch.Size([128])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: e4.norm\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.0.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.0.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.1.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.1.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.2.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.2.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.3.n1\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: bottleneck.3.n2\n",
      " running_mean: torch.Size([256])\n",
      " running_var : torch.Size([256])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d1.norm\n",
      " running_mean: torch.Size([128])\n",
      " running_var : torch.Size([128])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d2.norm\n",
      " running_mean: torch.Size([64])\n",
      " running_var : torch.Size([64])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d3.norm\n",
      " running_mean: torch.Size([32])\n",
      " running_var : torch.Size([32])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n",
      "\n",
      "BN layer: d4.norm\n",
      " running_mean: torch.Size([16])\n",
      " running_var : torch.Size([16])\n",
      " momentum    : 0.1\n",
      " eps         : 1e-05\n",
      " affine      : True\n"
     ]
    }
   ],
   "source": [
    "for name, module in G.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm1d):\n",
    "        print(f\"\\nBN layer: {name}\")\n",
    "        print(\" running_mean:\", module.running_mean.shape)\n",
    "        print(\" running_var :\", module.running_var.shape)\n",
    "        print(\" momentum    :\", module.momentum)\n",
    "        print(\" eps         :\", module.eps)\n",
    "        print(\" affine      :\", module.affine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ddfca",
   "metadata": {},
   "source": [
    "# Convolution and BatchNorm Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5ee3a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_bn_1d(\n",
    "    conv_weight,        # (Cout, Cin, K)\n",
    "    conv_bias,          # (Cout,) or None\n",
    "    running_mean,       # (Cout,)\n",
    "    running_var,        # (Cout,)\n",
    "    bn_weight,          # (Cout,) or None (gamma)\n",
    "    bn_bias,            # (Cout,) or None (beta)\n",
    "    eps=1e-5\n",
    "):\n",
    "    Cout = conv_weight.shape[0]\n",
    "\n",
    "    if bn_weight is None:\n",
    "        bn_weight = torch.ones(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "    if bn_bias is None:\n",
    "        bn_bias = torch.zeros(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "    if conv_bias is None:\n",
    "        conv_bias = torch.zeros(Cout, device=conv_weight.device, dtype=conv_weight.dtype)\n",
    "\n",
    "    denom = torch.sqrt(running_var + eps)          # (Cout,)\n",
    "    scale = bn_weight / denom                      # (Cout,)\n",
    "\n",
    "    # Fuse weight\n",
    "    fused_weight = conv_weight * scale[:, None, None]\n",
    "\n",
    "    # Fuse bias\n",
    "    fused_bias = (conv_bias - running_mean) * scale + bn_bias\n",
    "\n",
    "    return fused_weight, fused_bias\n",
    "\n",
    "def fuse_deconv_bn_1d(\n",
    "    deconv_weight,     # (Cin, Cout, K)\n",
    "    deconv_bias,       # (Cout,) or None\n",
    "    running_mean,      # (Cout,)\n",
    "    running_var,       # (Cout,)\n",
    "    bn_weight,         # (Cout,)\n",
    "    bn_bias,           # (Cout,)\n",
    "    eps\n",
    "):\n",
    "    Cin, Cout, K = deconv_weight.shape\n",
    "\n",
    "    if deconv_bias is None:\n",
    "        deconv_bias = torch.zeros(\n",
    "            Cout,\n",
    "            device=deconv_weight.device,\n",
    "            dtype=deconv_weight.dtype\n",
    "        )\n",
    "\n",
    "    # BN scale\n",
    "    scale = bn_weight / torch.sqrt(running_var + eps)  # (Cout,)\n",
    "\n",
    "    # Fuse weights (scale on Cout dimension)\n",
    "    fused_weight = deconv_weight * scale.view(1, Cout, 1)\n",
    "\n",
    "    # Fuse bias\n",
    "    fused_bias = (deconv_bias - running_mean) * scale + bn_bias\n",
    "\n",
    "    return fused_weight, fused_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8751c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedConvBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s, p, bias=True, act=\"lrelu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, k, s, p, bias=bias)\n",
    "\n",
    "        if act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class FusedDeconvBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, s, p, bias=True, act=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(in_ch, out_ch, k, s, p, bias=bias)\n",
    "\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        elif act == \"lrelu\":\n",
    "            self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.deconv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8c5afa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorCNNWGAN_Fused(nn.Module):\n",
    "    def __init__(self, base_ch=32, bottleneck_blocks=4, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e1 = FusedConvBlock1D(1, base_ch, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e2 = FusedConvBlock1D(base_ch, base_ch*2, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e3 = FusedConvBlock1D(base_ch*2, base_ch*4, 16, 2, 7, bias, \"lrelu\")\n",
    "        self.e4 = FusedConvBlock1D(base_ch*4, base_ch*8, 16, 2, 7, bias, \"lrelu\")\n",
    "\n",
    "        self.bottleneck = nn.Sequential(*[\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(base_ch*8, base_ch*8, 7, 1, 3, bias=bias),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(base_ch*8, base_ch*8, 7, 1, 3, bias=bias),\n",
    "            )\n",
    "            for _ in range(bottleneck_blocks)\n",
    "        ])\n",
    "\n",
    "        self.d1 = FusedDeconvBlock1D(base_ch*8, base_ch*4, 4, 2, 1, bias)\n",
    "        self.d2 = FusedDeconvBlock1D(base_ch*8, base_ch*2, 4, 2, 1, bias)\n",
    "        self.d3 = FusedDeconvBlock1D(base_ch*4, base_ch, 4, 2, 1, bias)\n",
    "        self.d4 = FusedDeconvBlock1D(base_ch*2, base_ch//2, 4, 2, 1, bias)\n",
    "\n",
    "        self.out = nn.Conv1d(base_ch//2, 1, 7, 1, 3, bias=bias)\n",
    "\n",
    "    def forward(self, y):\n",
    "        s1 = self.e1(y)\n",
    "        s2 = self.e2(s1)\n",
    "        s3 = self.e3(s2)\n",
    "        s4 = self.e4(s3)\n",
    "\n",
    "        b = s4\n",
    "        for blk in self.bottleneck:\n",
    "            b = F.relu(b + blk(b))\n",
    "\n",
    "        d1 = torch.cat([self.d1(b), s3], dim=1)\n",
    "        d2 = torch.cat([self.d2(d1), s2], dim=1)\n",
    "        d3 = torch.cat([self.d3(d2), s1], dim=1)\n",
    "        d4 = self.d4(d3)\n",
    "\n",
    "        return self.out(d4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7523ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_generator(G):\n",
    "    G_fused = GeneratorCNNWGAN_Fused(bias=True).to(device)\n",
    "    G_fused.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encoder\n",
    "        for i in range(1, 5):\n",
    "            e = getattr(G, f\"e{i}\")\n",
    "            fe = getattr(G_fused, f\"e{i}\")\n",
    "\n",
    "            w, b = fuse_conv_bn_1d(\n",
    "                e.conv.weight, e.conv.bias,\n",
    "                e.norm.running_mean, e.norm.running_var,\n",
    "                e.norm.weight, e.norm.bias\n",
    "            )\n",
    "            fe.conv.weight.copy_(w)\n",
    "            fe.conv.bias.copy_(b)\n",
    "\n",
    "        # Bottleneck\n",
    "        for i, blk in enumerate(G.bottleneck):\n",
    "            fblk = G_fused.bottleneck[i]\n",
    "\n",
    "            for j, (c, n) in enumerate([(blk.c1, blk.n1), (blk.c2, blk.n2)]):\n",
    "                w, b = fuse_conv_bn_1d(\n",
    "                    c.weight, c.bias,\n",
    "                    n.running_mean, n.running_var,\n",
    "                    n.weight, n.bias\n",
    "                )\n",
    "                fblk[j*2].weight.copy_(w)\n",
    "                fblk[j*2].bias.copy_(b)\n",
    "\n",
    "        # Decoder\n",
    "        for i in range(1, 5):\n",
    "            d = getattr(G, f\"d{i}\")\n",
    "            fd = getattr(G_fused, f\"d{i}\")\n",
    "\n",
    "            w, b = fuse_deconv_bn_1d(\n",
    "                d.deconv.weight, d.deconv.bias,\n",
    "                d.norm.running_mean, d.norm.running_var,\n",
    "                d.norm.weight, d.norm.bias,\n",
    "                d.norm.eps\n",
    "            )\n",
    "            fd.deconv.weight.copy_(w)\n",
    "            fd.deconv.bias.copy_(b)\n",
    "\n",
    "        # Output\n",
    "        G_fused.out.weight.copy_(G.out.weight)\n",
    "        G_fused.out.bias.copy_(G.out.bias)\n",
    "\n",
    "    return G_fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "356e4104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Aryo\\PersonalMade\\Programming\\GAN\\repo\\src\\models\\main3_d1_b\\fused_cnn_G_20260113_074150.pth\n"
     ]
    }
   ],
   "source": [
    "G_fused = fuse_generator(G)\n",
    "\n",
    "fused_G_path = os.path.join(\n",
    "    data_path,\n",
    "    \"fused_\" + os.path.basename(cnn_G_path)\n",
    ")\n",
    "\n",
    "torch.save(G_fused.state_dict(), fused_G_path)\n",
    "print(\"Saved:\", fused_G_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b9cd7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> GeneratorCNNWGAN_Fused\n",
      "e1 -> FusedConvBlock1D\n",
      "e1.conv -> Conv1d\n",
      "e1.act -> LeakyReLU\n",
      "e2 -> FusedConvBlock1D\n",
      "e2.conv -> Conv1d\n",
      "e2.act -> LeakyReLU\n",
      "e3 -> FusedConvBlock1D\n",
      "e3.conv -> Conv1d\n",
      "e3.act -> LeakyReLU\n",
      "e4 -> FusedConvBlock1D\n",
      "e4.conv -> Conv1d\n",
      "e4.act -> LeakyReLU\n",
      "bottleneck -> Sequential\n",
      "bottleneck.0 -> Sequential\n",
      "bottleneck.0.0 -> Conv1d\n",
      "bottleneck.0.1 -> ReLU\n",
      "bottleneck.0.2 -> Conv1d\n",
      "bottleneck.1 -> Sequential\n",
      "bottleneck.1.0 -> Conv1d\n",
      "bottleneck.1.1 -> ReLU\n",
      "bottleneck.1.2 -> Conv1d\n",
      "bottleneck.2 -> Sequential\n",
      "bottleneck.2.0 -> Conv1d\n",
      "bottleneck.2.1 -> ReLU\n",
      "bottleneck.2.2 -> Conv1d\n",
      "bottleneck.3 -> Sequential\n",
      "bottleneck.3.0 -> Conv1d\n",
      "bottleneck.3.1 -> ReLU\n",
      "bottleneck.3.2 -> Conv1d\n",
      "d1 -> FusedDeconvBlock1D\n",
      "d1.deconv -> ConvTranspose1d\n",
      "d1.act -> ReLU\n",
      "d2 -> FusedDeconvBlock1D\n",
      "d2.deconv -> ConvTranspose1d\n",
      "d2.act -> ReLU\n",
      "d3 -> FusedDeconvBlock1D\n",
      "d3.deconv -> ConvTranspose1d\n",
      "d3.act -> ReLU\n",
      "d4 -> FusedDeconvBlock1D\n",
      "d4.deconv -> ConvTranspose1d\n",
      "d4.act -> ReLU\n",
      "out -> Conv1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryo\\AppData\\Local\\Temp\\ipykernel_19204\\830450021.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G_check.load_state_dict(torch.load(fused_G_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "G_check = GeneratorCNNWGAN_Fused().to(device)\n",
    "G_check.load_state_dict(torch.load(fused_G_path, map_location=device))\n",
    "G_check.eval()\n",
    "\n",
    "for name, module in G_check.named_modules():\n",
    "    print(name, \"->\", module.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9e442771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Generator\n",
      "  Learnable parameters : 4,584,161\n",
      "  Buffers (BN stats)   : 5,552\n",
      "  TOTAL constants      : 4,589,713\n",
      "\n",
      "Fused Generator\n",
      "  Learnable parameters : 4,578,625\n",
      "  Buffers (BN stats)   : 0\n",
      "  TOTAL constants      : 4,578,625\n",
      "\n",
      "============================================================\n",
      "DIFFERENCE\n",
      "  Params removed  : 5,536\n",
      "  Buffers removed : 5,552\n",
      "  Total reduction : 11,088\n"
     ]
    }
   ],
   "source": [
    "def count_params_and_constants(model):\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    n_buffers = sum(b.numel() for b in model.buffers())\n",
    "    return n_params, n_buffers, n_params + n_buffers\n",
    "\n",
    "\n",
    "def pretty_count(name, model):\n",
    "    p, b, t = count_params_and_constants(model)\n",
    "    print(f\"{name}\")\n",
    "    print(f\"  Learnable parameters : {p:,}\")\n",
    "    print(f\"  Buffers (BN stats)   : {b:,}\")\n",
    "    print(f\"  TOTAL constants      : {t:,}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "pretty_count(\"Original Generator\", G)\n",
    "pretty_count(\"Fused Generator\", G_fused)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "p0, b0, t0 = count_params_and_constants(G)\n",
    "p1, b1, t1 = count_params_and_constants(G_fused)\n",
    "\n",
    "print(\"DIFFERENCE\")\n",
    "print(f\"  Params removed  : {p0 - p1:,}\")\n",
    "print(f\"  Buffers removed : {b0 - b1:,}\")\n",
    "print(f\"  Total reduction : {t0 - t1:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187c414",
   "metadata": {},
   "source": [
    "# Prepare for PYNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "bb3ca370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total floats: 4578625\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "offsets = {}\n",
    "\n",
    "cursor = 0\n",
    "for name, param in G_fused.state_dict().items():\n",
    "    arr = param.cpu().numpy().astype(np.float16)   \n",
    "    # arr = param.cpu().numpy().astype(np.float32)\n",
    "    size = arr.size\n",
    "\n",
    "    offsets[name] = {\n",
    "        \"offset\": int(cursor),\n",
    "        \"shape\": list(arr.shape),\n",
    "        \"dtype\": \"float16\"    \n",
    "    }\n",
    "\n",
    "    weights.append(arr.reshape(-1))\n",
    "    cursor += size\n",
    "\n",
    "weights_flat = np.concatenate(weights)\n",
    "\n",
    "weight_path = os.path.join(\n",
    "    os.path.dirname(fused_G_path),\n",
    "    f\"fused_cnn_G_d{DATA_MODE}b_weights.npy\"\n",
    ")\n",
    "offset_path = os.path.join(\n",
    "    os.path.dirname(fused_G_path),\n",
    "    f\"fused_cnn_G_d{DATA_MODE}b_offsets.json\"\n",
    ")\n",
    "np.save(weight_path, weights_flat)\n",
    "with open(offset_path, \"w\") as f:\n",
    "    json.dump(offsets, f, indent=2)\n",
    "\n",
    "print(\"Total floats:\", weights_flat.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "54819673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -2.121\n",
      "Max: 2.738\n",
      "Avg: -0.000262\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", weights_flat.min())\n",
    "print(\"Max:\", weights_flat.max())\n",
    "print(\"Avg:\", weights_flat.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
